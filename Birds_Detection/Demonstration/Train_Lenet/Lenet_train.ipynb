{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Pour la manipulation de tableaux\n",
    "from keras.applications import  resnet50\n",
    "from sklearn import metrics \n",
    "import os\n",
    "\n",
    "import pandas as pd # Pour manipuler des DataFrames pandas\n",
    "\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential # Pour construire un réseau de neurones\n",
    "from keras.layers import Dense, Conv2D # Pour instancier une couche dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import keras\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools # Pour créer des iterateurs\n",
    "\n",
    "from sklearn import linear_model, preprocessing \n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time, cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.1\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.1\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classe</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>imagetteName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_2019-06-14_15-46-54.jpg</td>\n",
       "      <td>corneille</td>\n",
       "      <td>709</td>\n",
       "      <td>305</td>\n",
       "      <td>722</td>\n",
       "      <td>317</td>\n",
       "      <td>image_2019-06-14_15-46-54_corneille_724.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2019-06-14_15-46-54.jpg</td>\n",
       "      <td>ground</td>\n",
       "      <td>694</td>\n",
       "      <td>306</td>\n",
       "      <td>706</td>\n",
       "      <td>319</td>\n",
       "      <td>image_2019-06-14_15-46-54_ground_725.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_2019-06-14_15-46-54.jpg</td>\n",
       "      <td>corneille</td>\n",
       "      <td>762</td>\n",
       "      <td>313</td>\n",
       "      <td>774</td>\n",
       "      <td>324</td>\n",
       "      <td>image_2019-06-14_15-46-54_corneille_726.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_2019-06-14_15-46-54.jpg</td>\n",
       "      <td>ground</td>\n",
       "      <td>778</td>\n",
       "      <td>311</td>\n",
       "      <td>790</td>\n",
       "      <td>322</td>\n",
       "      <td>image_2019-06-14_15-46-54_ground_727.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_2019-06-14_15-47-11.jpg</td>\n",
       "      <td>corneille</td>\n",
       "      <td>755</td>\n",
       "      <td>293</td>\n",
       "      <td>774</td>\n",
       "      <td>308</td>\n",
       "      <td>image_2019-06-14_15-47-11_corneille_728.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>image_2019-04-30_18-55-20.jpg</td>\n",
       "      <td>ground</td>\n",
       "      <td>393</td>\n",
       "      <td>494</td>\n",
       "      <td>403</td>\n",
       "      <td>506</td>\n",
       "      <td>image_2019-04-30_18-55-20_ground_6215.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>image_2019-04-30_18-55-20.jpg</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>625</td>\n",
       "      <td>423</td>\n",
       "      <td>633</td>\n",
       "      <td>431</td>\n",
       "      <td>image_2019-04-30_18-55-20_pigeon_6216.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>image_2019-04-30_18-55-20.jpg</td>\n",
       "      <td>ground</td>\n",
       "      <td>615</td>\n",
       "      <td>421</td>\n",
       "      <td>623</td>\n",
       "      <td>429</td>\n",
       "      <td>image_2019-04-30_18-55-20_ground_6217.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>image_2019-04-30_18-55-20.jpg</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>1119</td>\n",
       "      <td>399</td>\n",
       "      <td>1140</td>\n",
       "      <td>412</td>\n",
       "      <td>image_2019-04-30_18-55-20_pigeon_6218.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>image_2019-04-30_18-55-20.jpg</td>\n",
       "      <td>ground</td>\n",
       "      <td>1096</td>\n",
       "      <td>397</td>\n",
       "      <td>1117</td>\n",
       "      <td>410</td>\n",
       "      <td>image_2019-04-30_18-55-20_ground_6219.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename     classe  xmin  ymin  xmax  ymax  \\\n",
       "0     image_2019-06-14_15-46-54.jpg  corneille   709   305   722   317   \n",
       "1     image_2019-06-14_15-46-54.jpg     ground   694   306   706   319   \n",
       "2     image_2019-06-14_15-46-54.jpg  corneille   762   313   774   324   \n",
       "3     image_2019-06-14_15-46-54.jpg     ground   778   311   790   322   \n",
       "4     image_2019-06-14_15-47-11.jpg  corneille   755   293   774   308   \n",
       "...                             ...        ...   ...   ...   ...   ...   \n",
       "4513  image_2019-04-30_18-55-20.jpg     ground   393   494   403   506   \n",
       "4514  image_2019-04-30_18-55-20.jpg     pigeon   625   423   633   431   \n",
       "4515  image_2019-04-30_18-55-20.jpg     ground   615   421   623   429   \n",
       "4516  image_2019-04-30_18-55-20.jpg     pigeon  1119   399  1140   412   \n",
       "4517  image_2019-04-30_18-55-20.jpg     ground  1096   397  1117   410   \n",
       "\n",
       "                                     imagetteName  \n",
       "0     image_2019-06-14_15-46-54_corneille_724.JPG  \n",
       "1        image_2019-06-14_15-46-54_ground_725.JPG  \n",
       "2     image_2019-06-14_15-46-54_corneille_726.JPG  \n",
       "3        image_2019-06-14_15-46-54_ground_727.JPG  \n",
       "4     image_2019-06-14_15-47-11_corneille_728.JPG  \n",
       "...                                           ...  \n",
       "4513    image_2019-04-30_18-55-20_ground_6215.JPG  \n",
       "4514    image_2019-04-30_18-55-20_pigeon_6216.JPG  \n",
       "4515    image_2019-04-30_18-55-20_ground_6217.JPG  \n",
       "4516    image_2019-04-30_18-55-20_pigeon_6218.JPG  \n",
       "4517    image_2019-04-30_18-55-20_ground_6219.JPG  \n",
       "\n",
       "[4518 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['corneille', 'ground', 'faisan', 'autre', 'ciel', 'lapin',\n",
       "       'chevreuil', 'pigeon', 'incertain', 'cheval'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_path=\"../../Materiels/images.csv\"\n",
    "Images=pd.read_csv(image_path)\n",
    "Images[\"classe\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimum_Number_Class=100\n",
    "def eliminate_small_categories(df,Minimum_Number_Class):\n",
    "    numerous_labels_=[]\n",
    "    all_labels_=df[\"classe\"].unique()\n",
    "    print(\"This is the list of different labels (acccording to the DataFrame) :\",df[\"classe\"].unique())\n",
    "    print(\"Images are now deleting from data base if the population are below \",Minimum_Number_Class)  \n",
    "    for i in df[\"classe\"].unique():\n",
    "        if df[\"classe\"][df[\"classe\"]==i].count()>Minimum_Number_Class:\n",
    "            numerous_labels_.append(i)\n",
    "\n",
    "    less_numerous_labels_=set(all_labels_)-set(Utilisable)\n",
    "    #print(Non_Utilisable,\"Non_Utilisable\")\n",
    "    for i in less_numerous_labels_:\n",
    "        df=df[df[\"classe\"]!=i] \n",
    "\n",
    "    print(\"This is the list of labels keep:\", df[\"classe\"].unique())\n",
    "    return df\n",
    "    \n",
    "df=eliminate_small_categories(Images,Minimum_Number_Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed(1)\n",
    "#tensorflow.random.set_seed(2)\n",
    "test_size=0.2\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"classe\"], test_size=test_size,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_range=1.1\n",
    "horizontal_flip=False\n",
    "batch_size=16\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        # data augmentation\n",
    "        rotation_range = 10,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3594 validated image filenames belonging to 6 classes.\n",
      "Found 899 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"../../../../Pic_dataset\",\n",
    "                                                           x_col = \"filename\",\n",
    "                                                           y_col = \"classe\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"../../../../Pic_dataset\",\n",
    "                                                           x_col = \"filename\",\n",
    "                                                            y_col = \"classe\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n",
    "NB_CLASSES=len(set(train_generator.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lenet_archi(NB_CLASSES,dropout_rate):\n",
    "    lenet = Sequential()\n",
    "\n",
    "    conv_1 = Conv2D(filters = 30,                     # Nombre de filtres\n",
    "                    kernel_size = (5, 5),            # Dimensions du noyau\n",
    "                    padding = 'valid',               # Mode de Dépassement\n",
    "                    input_shape = (28, 28, 3),       # Dimensions de l'image en entrée\n",
    "                    activation = 'relu')             # Fonction d'activation\n",
    "\n",
    "    max_pool_1 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "    conv_2 = Conv2D(filters = 16,                    \n",
    "                    kernel_size = (3, 3),          \n",
    "                    padding = 'valid',             \n",
    "                    activation = 'relu')\n",
    "\n",
    "    max_pool_2 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "    flatten = Flatten()\n",
    "\n",
    "    dropout = Dropout(rate = dropout_rate)\n",
    "\n",
    "    dense_1 = Dense(units = 128,\n",
    "                    activation = 'relu')\n",
    "\n",
    "    dense_2 = Dense(units = 6,\n",
    "                    activation = 'softmax')\n",
    "\n",
    "    lenet.add(conv_1)\n",
    "    lenet.add(max_pool_1)\n",
    "    lenet.add(conv_2)\n",
    "    lenet.add(max_pool_2)\n",
    "    lenet.add(dropout)\n",
    "    lenet.add(flatten)\n",
    "    lenet.add(dense_1)\n",
    "    lenet.add(dense_2)\n",
    "    \n",
    "    return lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "dropout_rate=0.5\n",
    "nn=Lenet_archi(NB_CLASSES,dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation\n",
    "nn.compile(loss='sparse_categorical_crossentropy',  # fonction de perte\n",
    "              optimizer='adam',                 # algorithme de descente de gradient\n",
    "              metrics=['accuracy'])             # métrique d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "224/224 [==============================] - 167s 747ms/step - loss: 8.3032 - acc: 0.4788 - val_loss: 8.0231 - val_acc: 0.5022\n",
      "Epoch 2/2\n",
      "224/224 [==============================] - 153s 685ms/step - loss: 7.9790 - acc: 0.5050 - val_loss: 8.0499 - val_acc: 0.5006\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6f2d2b1b1ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=2\n",
    "history=nn.fit_generator( train_generator,\n",
    "                           steps_per_epoch=len(data_train)//batch_size,\n",
    "                           epochs=epochs,\n",
    "                           workers=-1,\n",
    "                           validation_data=test_generator,\n",
    "                           validation_steps=len(data_test)//batch_size)\n",
    "                          \n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.plot(history.history['accuracy'],label=\"train\");\n",
    "plt.plot(history.history['val_accuracy'],label=\"test\");\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy en fonction du nombre d'epoch\");\n",
    "plt.legend();\n",
    "#drop_out.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
