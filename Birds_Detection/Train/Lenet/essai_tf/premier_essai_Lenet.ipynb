{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'abord vérifier si on a du Lenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essayons de faire lenet avec tf voir ci-dessous . Il y a aussi une commande pour voir le résumer peut être .resume\n",
    "def build_model(width, height, depth, classes,drop_out_rate):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(30, (5, 5), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(128),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(drop_out_rate),\n",
    "        \n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dropout_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-75bab66b2c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m dense_1 = Dense(units = 128,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dropout_rate' is not defined"
     ]
    }
   ],
   "source": [
    "  \n",
    "    \n",
    "    lenet = Sequential()\n",
    "\n",
    "    conv_1 = Conv2D(filters = 30,                     # Nombre de filtres\n",
    "                kernel_size = (5, 5),            # Dimensions du noyau\n",
    "                padding = 'valid',               # Mode de Dépassement\n",
    "                input_shape = (28, 28, 3),       # Dimensions de l'image en entrée\n",
    "                activation = 'relu')             # Fonction d'activation\n",
    "\n",
    "    max_pool_1 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "    conv_2 = Conv2D(filters = 16,                    \n",
    "                kernel_size = (3, 3),          \n",
    "                padding = 'valid',             \n",
    "                activation = 'relu')\n",
    "\n",
    "    max_pool_2 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "    flatten = Flatten()\n",
    "\n",
    "    dropout = Dropout(rate = dropout_rate)\n",
    "\n",
    "    dense_1 = Dense(units = 128,\n",
    "                activation = 'relu')\n",
    "\n",
    "    dense_2 = Dense(units = 6,\n",
    "                activation = 'softmax')\n",
    "\n",
    "    lenet.add(conv_1)\n",
    "    lenet.add(max_pool_1)\n",
    "    lenet.add(conv_2)\n",
    "    lenet.add(max_pool_2)\n",
    "    lenet.add(dropout)\n",
    "    lenet.add(flatten)\n",
    "    lenet.add(dense_1)\n",
    "    lenet.add(dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_2.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_3.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0258_pigeon_4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0335_pigeon_8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0341_pigeon_10.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                            img_paths\n",
       "2   corneille  Rec_images/DSCF0180_corneille_2.JPG\n",
       "3   corneille  Rec_images/DSCF0180_corneille_3.JPG\n",
       "4      pigeon     Rec_images/DSCF0258_pigeon_4.JPG\n",
       "8      pigeon     Rec_images/DSCF0335_pigeon_8.JPG\n",
       "10     pigeon    Rec_images/DSCF0341_pigeon_10.JPG"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/home/marcpozzo/Desktop/c3po/Images_aquises/generateur.csv\")\n",
    "df=df[(df[\"class\"]=='corneille') | (df[\"class\"]=='pigeon') | (df[\"class\"]=='faisan')   ]\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.2\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.3\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4772 validated image filenames belonging to 6 classes.\n",
      "Found 1194 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        #preprocessing_function = preprocess_input,\n",
    "        # data augmentation\n",
    "        rotation_range = 10,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator()\n",
    "    #preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_train) )\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_test))\n",
    "\n",
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3df7f71ae42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#seed(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#seed(1)\n",
    "tf.random.set_seed(2)\n",
    "model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4772 samples, validate on 1194 samples\n",
      "Epoch 1/200\n",
      "4772/4772 [==============================] - 3s 706us/sample - loss: 1.2703 - acc: 0.5953 - val_loss: 1.1944 - val_acc: 0.5913\n",
      "Epoch 2/200\n",
      "4772/4772 [==============================] - 3s 567us/sample - loss: 0.8039 - acc: 0.7513 - val_loss: 0.7747 - val_acc: 0.7437\n",
      "Epoch 3/200\n",
      "4772/4772 [==============================] - 3s 568us/sample - loss: 0.7599 - acc: 0.7554 - val_loss: 0.8747 - val_acc: 0.6499\n",
      "Epoch 4/200\n",
      "4772/4772 [==============================] - 3s 569us/sample - loss: 0.6840 - acc: 0.7766 - val_loss: 0.8242 - val_acc: 0.7663\n",
      "Epoch 5/200\n",
      "4772/4772 [==============================] - 3s 555us/sample - loss: 0.6144 - acc: 0.8104 - val_loss: 0.6598 - val_acc: 0.7864\n",
      "Epoch 6/200\n",
      "4772/4772 [==============================] - 3s 572us/sample - loss: 0.5587 - acc: 0.8198 - val_loss: 0.7574 - val_acc: 0.7806\n",
      "Epoch 7/200\n",
      "4772/4772 [==============================] - 3s 564us/sample - loss: 0.5578 - acc: 0.8225 - val_loss: 0.6016 - val_acc: 0.8191\n",
      "Epoch 8/200\n",
      "4772/4772 [==============================] - 3s 577us/sample - loss: 0.5611 - acc: 0.8204 - val_loss: 1.2468 - val_acc: 0.7127\n",
      "Epoch 9/200\n",
      "4772/4772 [==============================] - 3s 557us/sample - loss: 0.5216 - acc: 0.8330 - val_loss: 0.8746 - val_acc: 0.7437\n",
      "Epoch 10/200\n",
      "4772/4772 [==============================] - 3s 572us/sample - loss: 0.4803 - acc: 0.8504 - val_loss: 0.5918 - val_acc: 0.8266\n",
      "Epoch 11/200\n",
      "4772/4772 [==============================] - 3s 563us/sample - loss: 0.5027 - acc: 0.8409 - val_loss: 0.5218 - val_acc: 0.8752\n",
      "Epoch 12/200\n",
      "4772/4772 [==============================] - 3s 568us/sample - loss: 0.5265 - acc: 0.8286 - val_loss: 0.4585 - val_acc: 0.8543\n",
      "Epoch 13/200\n",
      "4772/4772 [==============================] - 3s 558us/sample - loss: 0.4680 - acc: 0.8502 - val_loss: 0.5029 - val_acc: 0.8367\n",
      "Epoch 14/200\n",
      "4772/4772 [==============================] - 3s 570us/sample - loss: 0.4455 - acc: 0.8619 - val_loss: 0.6243 - val_acc: 0.8049\n",
      "Epoch 15/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.4270 - acc: 0.8617 - val_loss: 0.4852 - val_acc: 0.8559\n",
      "Epoch 16/200\n",
      "4772/4772 [==============================] - 3s 558us/sample - loss: 0.4180 - acc: 0.8653 - val_loss: 0.4700 - val_acc: 0.8476\n",
      "Epoch 17/200\n",
      "4772/4772 [==============================] - 3s 556us/sample - loss: 0.3964 - acc: 0.8751 - val_loss: 0.4395 - val_acc: 0.8534\n",
      "Epoch 18/200\n",
      "4772/4772 [==============================] - 3s 557us/sample - loss: 0.3905 - acc: 0.8762 - val_loss: 0.3879 - val_acc: 0.8894\n",
      "Epoch 19/200\n",
      "4772/4772 [==============================] - 3s 567us/sample - loss: 0.4035 - acc: 0.8661 - val_loss: 24.6473 - val_acc: 0.2848\n",
      "Epoch 20/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.4453 - acc: 0.8596 - val_loss: 0.4500 - val_acc: 0.8802\n",
      "Epoch 21/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.4398 - acc: 0.8627 - val_loss: 1.1561 - val_acc: 0.7370\n",
      "Epoch 22/200\n",
      "4772/4772 [==============================] - 3s 567us/sample - loss: 0.3952 - acc: 0.8734 - val_loss: 0.3792 - val_acc: 0.8920\n",
      "Epoch 23/200\n",
      "4772/4772 [==============================] - 3s 531us/sample - loss: 0.3773 - acc: 0.8799 - val_loss: 0.4238 - val_acc: 0.8635\n",
      "Epoch 24/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.3734 - acc: 0.8814 - val_loss: 0.3523 - val_acc: 0.9020\n",
      "Epoch 25/200\n",
      "4772/4772 [==============================] - 3s 549us/sample - loss: 0.3531 - acc: 0.8942 - val_loss: 0.4253 - val_acc: 0.8794\n",
      "Epoch 26/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.3445 - acc: 0.8904 - val_loss: 0.5833 - val_acc: 0.8585\n",
      "Epoch 27/200\n",
      "4772/4772 [==============================] - 3s 553us/sample - loss: 0.3346 - acc: 0.8948 - val_loss: 0.3188 - val_acc: 0.9062\n",
      "Epoch 28/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.3214 - acc: 0.8956 - val_loss: 0.4453 - val_acc: 0.8668\n",
      "Epoch 29/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.3120 - acc: 0.9013 - val_loss: 0.3533 - val_acc: 0.8911\n",
      "Epoch 30/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.3049 - acc: 0.9053 - val_loss: 0.6075 - val_acc: 0.7831\n",
      "Epoch 31/200\n",
      "4772/4772 [==============================] - 3s 530us/sample - loss: 0.3297 - acc: 0.8952 - val_loss: 0.3707 - val_acc: 0.8869\n",
      "Epoch 32/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.3048 - acc: 0.9074 - val_loss: 0.4262 - val_acc: 0.8526\n",
      "Epoch 33/200\n",
      "4772/4772 [==============================] - 3s 547us/sample - loss: 0.3231 - acc: 0.8967 - val_loss: 0.4125 - val_acc: 0.9028\n",
      "Epoch 34/200\n",
      "4772/4772 [==============================] - 3s 552us/sample - loss: 0.2951 - acc: 0.9067 - val_loss: 0.4511 - val_acc: 0.8802\n",
      "Epoch 35/200\n",
      "4772/4772 [==============================] - 3s 541us/sample - loss: 0.2792 - acc: 0.9103 - val_loss: 0.5924 - val_acc: 0.8451\n",
      "Epoch 36/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.2981 - acc: 0.9011 - val_loss: 0.3521 - val_acc: 0.9087\n",
      "Epoch 37/200\n",
      "4772/4772 [==============================] - ETA: 0s - loss: 0.2616 - acc: 0.916 - 3s 542us/sample - loss: 0.2636 - acc: 0.9162 - val_loss: 0.4428 - val_acc: 0.8827\n",
      "Epoch 38/200\n",
      "4772/4772 [==============================] - 3s 542us/sample - loss: 0.3242 - acc: 0.8902 - val_loss: 0.3411 - val_acc: 0.9112\n",
      "Epoch 39/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.2791 - acc: 0.9116 - val_loss: 0.4525 - val_acc: 0.8752\n",
      "Epoch 40/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.2787 - acc: 0.9063 - val_loss: 0.3963 - val_acc: 0.8794\n",
      "Epoch 41/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.2709 - acc: 0.9141 - val_loss: 0.3512 - val_acc: 0.9129\n",
      "Epoch 42/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.2956 - acc: 0.9059 - val_loss: 0.3622 - val_acc: 0.9028\n",
      "Epoch 43/200\n",
      "4772/4772 [==============================] - 3s 546us/sample - loss: 0.2541 - acc: 0.9179 - val_loss: 0.3876 - val_acc: 0.8903\n",
      "Epoch 44/200\n",
      "4772/4772 [==============================] - 3s 527us/sample - loss: 0.2997 - acc: 0.9038 - val_loss: 0.3795 - val_acc: 0.8970\n",
      "Epoch 45/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.3618 - acc: 0.8845 - val_loss: 0.6276 - val_acc: 0.7446\n",
      "Epoch 46/200\n",
      "4772/4772 [==============================] - 3s 542us/sample - loss: 0.3820 - acc: 0.8755 - val_loss: 0.5666 - val_acc: 0.8970\n",
      "Epoch 47/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.2917 - acc: 0.9055 - val_loss: 0.4087 - val_acc: 0.8853\n",
      "Epoch 48/200\n",
      "4772/4772 [==============================] - 3s 549us/sample - loss: 0.2823 - acc: 0.9122 - val_loss: 0.3879 - val_acc: 0.8903\n",
      "Epoch 49/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.2548 - acc: 0.9187 - val_loss: 0.3708 - val_acc: 0.8903\n",
      "Epoch 50/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.2461 - acc: 0.9237 - val_loss: 0.3402 - val_acc: 0.9020\n",
      "Epoch 51/200\n",
      "4772/4772 [==============================] - 3s 526us/sample - loss: 0.2365 - acc: 0.9250 - val_loss: 0.3679 - val_acc: 0.8995\n",
      "Epoch 52/200\n",
      "4772/4772 [==============================] - 3s 547us/sample - loss: 0.2123 - acc: 0.9329 - val_loss: 0.3850 - val_acc: 0.8920\n",
      "Epoch 53/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.2464 - acc: 0.9231 - val_loss: 0.3770 - val_acc: 0.8995\n",
      "Epoch 54/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.2280 - acc: 0.9241 - val_loss: 0.3301 - val_acc: 0.8987\n",
      "Epoch 55/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.2220 - acc: 0.9279 - val_loss: 0.3973 - val_acc: 0.8819\n",
      "Epoch 56/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.2095 - acc: 0.9304 - val_loss: 0.4336 - val_acc: 0.8635\n",
      "Epoch 57/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.2455 - acc: 0.9229 - val_loss: 0.3779 - val_acc: 0.8961\n",
      "Epoch 58/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.2093 - acc: 0.9334 - val_loss: 0.3700 - val_acc: 0.8886\n",
      "Epoch 59/200\n",
      "4772/4772 [==============================] - 3s 555us/sample - loss: 0.3728 - acc: 0.8810 - val_loss: 0.5741 - val_acc: 0.8392\n",
      "Epoch 60/200\n",
      "4772/4772 [==============================] - 3s 532us/sample - loss: 0.2540 - acc: 0.9172 - val_loss: 0.5320 - val_acc: 0.8090\n",
      "Epoch 61/200\n",
      "4772/4772 [==============================] - 3s 549us/sample - loss: 0.2383 - acc: 0.9244 - val_loss: 0.3272 - val_acc: 0.9104\n",
      "Epoch 62/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.2212 - acc: 0.9279 - val_loss: 0.3009 - val_acc: 0.9146\n",
      "Epoch 63/200\n",
      "4772/4772 [==============================] - 3s 555us/sample - loss: 0.2023 - acc: 0.9334 - val_loss: 0.3717 - val_acc: 0.8920\n",
      "Epoch 64/200\n",
      "4772/4772 [==============================] - 3s 561us/sample - loss: 0.2771 - acc: 0.9130 - val_loss: 0.3625 - val_acc: 0.9054\n",
      "Epoch 65/200\n",
      "4772/4772 [==============================] - 3s 579us/sample - loss: 0.2602 - acc: 0.9212 - val_loss: 0.3684 - val_acc: 0.8936\n",
      "Epoch 66/200\n",
      "4772/4772 [==============================] - 3s 571us/sample - loss: 0.2422 - acc: 0.9250 - val_loss: 0.5678 - val_acc: 0.8233\n",
      "Epoch 67/200\n",
      "4772/4772 [==============================] - 3s 565us/sample - loss: 0.2646 - acc: 0.9107 - val_loss: 0.3857 - val_acc: 0.8886\n",
      "Epoch 68/200\n",
      "4772/4772 [==============================] - 3s 559us/sample - loss: 0.2085 - acc: 0.9340 - val_loss: 0.3697 - val_acc: 0.9037\n",
      "Epoch 69/200\n",
      "4772/4772 [==============================] - 3s 559us/sample - loss: 0.1837 - acc: 0.9430 - val_loss: 0.5027 - val_acc: 0.8626\n",
      "Epoch 70/200\n",
      "4772/4772 [==============================] - 3s 560us/sample - loss: 0.2423 - acc: 0.9246 - val_loss: 0.3432 - val_acc: 0.9028\n",
      "Epoch 71/200\n",
      "4772/4772 [==============================] - 3s 555us/sample - loss: 0.2017 - acc: 0.9359 - val_loss: 0.3914 - val_acc: 0.8945\n",
      "Epoch 72/200\n",
      "4772/4772 [==============================] - 3s 553us/sample - loss: 0.2168 - acc: 0.9332 - val_loss: 0.3297 - val_acc: 0.9095\n",
      "Epoch 73/200\n",
      "4772/4772 [==============================] - 3s 564us/sample - loss: 0.2051 - acc: 0.9340 - val_loss: 0.3334 - val_acc: 0.9037\n",
      "Epoch 74/200\n",
      "4772/4772 [==============================] - 3s 566us/sample - loss: 0.2199 - acc: 0.9357 - val_loss: 0.4899 - val_acc: 0.9137\n",
      "Epoch 75/200\n",
      "4772/4772 [==============================] - 3s 561us/sample - loss: 0.1772 - acc: 0.9443 - val_loss: 0.4378 - val_acc: 0.8853\n",
      "Epoch 76/200\n",
      "4772/4772 [==============================] - 3s 563us/sample - loss: 0.3057 - acc: 0.9011 - val_loss: 0.6748 - val_acc: 0.9045\n",
      "Epoch 77/200\n",
      "4772/4772 [==============================] - 3s 575us/sample - loss: 0.2016 - acc: 0.9346 - val_loss: 0.4058 - val_acc: 0.8819\n",
      "Epoch 78/200\n",
      "4772/4772 [==============================] - 3s 566us/sample - loss: 0.1913 - acc: 0.9394 - val_loss: 0.3190 - val_acc: 0.9129\n",
      "Epoch 79/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.1689 - acc: 0.9461 - val_loss: 0.4104 - val_acc: 0.8911\n",
      "Epoch 80/200\n",
      "4772/4772 [==============================] - 3s 565us/sample - loss: 0.2004 - acc: 0.9350 - val_loss: 0.3582 - val_acc: 0.9062\n",
      "Epoch 81/200\n",
      "4772/4772 [==============================] - 3s 557us/sample - loss: 0.1726 - acc: 0.9443 - val_loss: 0.4023 - val_acc: 0.8936\n",
      "Epoch 82/200\n",
      "4772/4772 [==============================] - 3s 561us/sample - loss: 0.1667 - acc: 0.9449 - val_loss: 0.3986 - val_acc: 0.9028\n",
      "Epoch 83/200\n",
      "4772/4772 [==============================] - 3s 561us/sample - loss: 0.1568 - acc: 0.9549 - val_loss: 0.3816 - val_acc: 0.8911\n",
      "Epoch 84/200\n",
      "4772/4772 [==============================] - 3s 566us/sample - loss: 0.1923 - acc: 0.9386 - val_loss: 0.5399 - val_acc: 0.8417\n",
      "Epoch 85/200\n",
      "4772/4772 [==============================] - 3s 555us/sample - loss: 0.1647 - acc: 0.9466 - val_loss: 0.3665 - val_acc: 0.8945\n",
      "Epoch 86/200\n",
      "4772/4772 [==============================] - 3s 566us/sample - loss: 0.1877 - acc: 0.9390 - val_loss: 0.3925 - val_acc: 0.8953\n",
      "Epoch 87/200\n",
      "4772/4772 [==============================] - 3s 556us/sample - loss: 0.1573 - acc: 0.9484 - val_loss: 0.4166 - val_acc: 0.8886\n",
      "Epoch 88/200\n",
      "4772/4772 [==============================] - 3s 562us/sample - loss: 0.1617 - acc: 0.9472 - val_loss: 0.4395 - val_acc: 0.8911\n",
      "Epoch 89/200\n",
      "4772/4772 [==============================] - 3s 574us/sample - loss: 0.1556 - acc: 0.9497 - val_loss: 0.3425 - val_acc: 0.9104\n",
      "Epoch 90/200\n",
      "4772/4772 [==============================] - 3s 568us/sample - loss: 0.1693 - acc: 0.9434 - val_loss: 0.4008 - val_acc: 0.8928\n",
      "Epoch 91/200\n",
      "4772/4772 [==============================] - 3s 579us/sample - loss: 0.1564 - acc: 0.9505 - val_loss: 0.4071 - val_acc: 0.9003\n",
      "Epoch 92/200\n",
      "4772/4772 [==============================] - 3s 562us/sample - loss: 0.1475 - acc: 0.9545 - val_loss: 0.4018 - val_acc: 0.8995\n",
      "Epoch 93/200\n",
      "4772/4772 [==============================] - 3s 562us/sample - loss: 0.1435 - acc: 0.9547 - val_loss: 0.3956 - val_acc: 0.9012\n",
      "Epoch 94/200\n",
      "4772/4772 [==============================] - 3s 572us/sample - loss: 0.1517 - acc: 0.9501 - val_loss: 0.4578 - val_acc: 0.8836\n",
      "Epoch 95/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.1714 - acc: 0.9470 - val_loss: 0.4086 - val_acc: 0.8920\n",
      "Epoch 96/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.1551 - acc: 0.9489 - val_loss: 0.5026 - val_acc: 0.8635\n",
      "Epoch 97/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.1605 - acc: 0.9489 - val_loss: 0.3942 - val_acc: 0.8987\n",
      "Epoch 98/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.1285 - acc: 0.9602 - val_loss: 0.4209 - val_acc: 0.8953\n",
      "Epoch 99/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.1791 - acc: 0.9417 - val_loss: 0.4468 - val_acc: 0.8836\n",
      "Epoch 100/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1490 - acc: 0.9543 - val_loss: 0.5427 - val_acc: 0.8585\n",
      "Epoch 101/200\n",
      "4772/4772 [==============================] - 3s 530us/sample - loss: 0.1756 - acc: 0.9430 - val_loss: 0.5921 - val_acc: 0.8878\n",
      "Epoch 102/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.2103 - acc: 0.9315 - val_loss: 0.4297 - val_acc: 0.8928\n",
      "Epoch 103/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.1584 - acc: 0.9505 - val_loss: 0.4618 - val_acc: 0.8987\n",
      "Epoch 104/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.1635 - acc: 0.9438 - val_loss: 0.4295 - val_acc: 0.9137\n",
      "Epoch 105/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.1422 - acc: 0.9533 - val_loss: 0.4125 - val_acc: 0.8961\n",
      "Epoch 106/200\n",
      "4772/4772 [==============================] - 3s 527us/sample - loss: 0.1540 - acc: 0.9520 - val_loss: 0.3917 - val_acc: 0.8911\n",
      "Epoch 107/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.1462 - acc: 0.9524 - val_loss: 0.3798 - val_acc: 0.8987\n",
      "Epoch 108/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.1864 - acc: 0.9373 - val_loss: 0.4498 - val_acc: 0.8903\n",
      "Epoch 109/200\n",
      "4772/4772 [==============================] - 3s 532us/sample - loss: 0.1518 - acc: 0.9508 - val_loss: 0.3678 - val_acc: 0.9054\n",
      "Epoch 110/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.1262 - acc: 0.9596 - val_loss: 0.3870 - val_acc: 0.9079\n",
      "Epoch 111/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.1377 - acc: 0.9556 - val_loss: 0.3727 - val_acc: 0.9028\n",
      "Epoch 112/200\n",
      "4772/4772 [==============================] - 3s 541us/sample - loss: 0.1471 - acc: 0.9528 - val_loss: 0.3852 - val_acc: 0.9028\n",
      "Epoch 113/200\n",
      "4772/4772 [==============================] - 3s 527us/sample - loss: 0.1299 - acc: 0.9606 - val_loss: 0.3880 - val_acc: 0.8970\n",
      "Epoch 114/200\n",
      "4772/4772 [==============================] - 3s 531us/sample - loss: 0.1222 - acc: 0.9598 - val_loss: 0.5340 - val_acc: 0.8409\n",
      "Epoch 115/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.1270 - acc: 0.9596 - val_loss: 0.5109 - val_acc: 0.8802\n",
      "Epoch 116/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.2475 - acc: 0.9220 - val_loss: 0.4706 - val_acc: 0.8467\n",
      "Epoch 117/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.1914 - acc: 0.9373 - val_loss: 0.5470 - val_acc: 0.8769\n",
      "Epoch 118/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.1623 - acc: 0.9478 - val_loss: 0.5025 - val_acc: 0.8652\n",
      "Epoch 119/200\n",
      "4772/4772 [==============================] - 3s 547us/sample - loss: 0.1404 - acc: 0.9537 - val_loss: 0.3959 - val_acc: 0.9070\n",
      "Epoch 120/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.1338 - acc: 0.9547 - val_loss: 0.3750 - val_acc: 0.9095\n",
      "Epoch 121/200\n",
      "4772/4772 [==============================] - 3s 542us/sample - loss: 0.1211 - acc: 0.9598 - val_loss: 0.4629 - val_acc: 0.8903\n",
      "Epoch 122/200\n",
      "4772/4772 [==============================] - 3s 531us/sample - loss: 0.1213 - acc: 0.9617 - val_loss: 0.4905 - val_acc: 0.8853\n",
      "Epoch 123/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.1177 - acc: 0.9621 - val_loss: 0.4374 - val_acc: 0.8928\n",
      "Epoch 124/200\n",
      "4772/4772 [==============================] - 3s 542us/sample - loss: 0.1362 - acc: 0.9560 - val_loss: 0.4239 - val_acc: 0.9028\n",
      "Epoch 125/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.1112 - acc: 0.9629 - val_loss: 0.4629 - val_acc: 0.9028\n",
      "Epoch 126/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.2141 - acc: 0.9304 - val_loss: 0.4662 - val_acc: 0.8861\n",
      "Epoch 127/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.1669 - acc: 0.9457 - val_loss: 0.4231 - val_acc: 0.8911\n",
      "Epoch 128/200\n",
      "4772/4772 [==============================] - 3s 554us/sample - loss: 0.1293 - acc: 0.9583 - val_loss: 0.4207 - val_acc: 0.8987\n",
      "Epoch 129/200\n",
      "4772/4772 [==============================] - 2s 522us/sample - loss: 0.1282 - acc: 0.9573 - val_loss: 0.4375 - val_acc: 0.8869\n",
      "Epoch 130/200\n",
      "4772/4772 [==============================] - 3s 541us/sample - loss: 0.1121 - acc: 0.9637 - val_loss: 0.4952 - val_acc: 0.8811\n",
      "Epoch 131/200\n",
      "4772/4772 [==============================] - 3s 530us/sample - loss: 0.1298 - acc: 0.9560 - val_loss: 0.4490 - val_acc: 0.8995\n",
      "Epoch 132/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.1268 - acc: 0.9598 - val_loss: 0.5032 - val_acc: 0.8903\n",
      "Epoch 133/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.1256 - acc: 0.9577 - val_loss: 0.4838 - val_acc: 0.8928\n",
      "Epoch 134/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1198 - acc: 0.9625 - val_loss: 0.4901 - val_acc: 0.8987\n",
      "Epoch 135/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1109 - acc: 0.9600 - val_loss: 0.4408 - val_acc: 0.9037\n",
      "Epoch 136/200\n",
      "4772/4772 [==============================] - 3s 527us/sample - loss: 0.1278 - acc: 0.9543 - val_loss: 0.4649 - val_acc: 0.8961\n",
      "Epoch 137/200\n",
      "4772/4772 [==============================] - 3s 526us/sample - loss: 0.1213 - acc: 0.9593 - val_loss: 0.4756 - val_acc: 0.8936\n",
      "Epoch 138/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.1173 - acc: 0.9606 - val_loss: 0.4968 - val_acc: 0.8861\n",
      "Epoch 139/200\n",
      "4772/4772 [==============================] - 2s 524us/sample - loss: 0.1090 - acc: 0.9648 - val_loss: 0.5169 - val_acc: 0.8794\n",
      "Epoch 140/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.1130 - acc: 0.9658 - val_loss: 0.4816 - val_acc: 0.8819\n",
      "Epoch 141/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.1493 - acc: 0.9524 - val_loss: 0.5451 - val_acc: 0.8702\n",
      "Epoch 142/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.1195 - acc: 0.9608 - val_loss: 0.5054 - val_acc: 0.8869\n",
      "Epoch 143/200\n",
      "4772/4772 [==============================] - 3s 532us/sample - loss: 0.1260 - acc: 0.9596 - val_loss: 0.5068 - val_acc: 0.8853\n",
      "Epoch 144/200\n",
      "4772/4772 [==============================] - 3s 528us/sample - loss: 0.1180 - acc: 0.9623 - val_loss: 0.4809 - val_acc: 0.8920\n",
      "Epoch 145/200\n",
      "4772/4772 [==============================] - 3s 532us/sample - loss: 0.1034 - acc: 0.9684 - val_loss: 0.3985 - val_acc: 0.9112\n",
      "Epoch 146/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1050 - acc: 0.9679 - val_loss: 0.4682 - val_acc: 0.8827\n",
      "Epoch 147/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1388 - acc: 0.9589 - val_loss: 0.5564 - val_acc: 0.8760\n",
      "Epoch 148/200\n",
      "4772/4772 [==============================] - 2s 519us/sample - loss: 0.1122 - acc: 0.9612 - val_loss: 0.4430 - val_acc: 0.8894\n",
      "Epoch 149/200\n",
      "4772/4772 [==============================] - 3s 532us/sample - loss: 0.0926 - acc: 0.9700 - val_loss: 2.8385 - val_acc: 0.8853\n",
      "Epoch 150/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.1231 - acc: 0.9619 - val_loss: 0.4854 - val_acc: 0.8953\n",
      "Epoch 151/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.1173 - acc: 0.9577 - val_loss: 0.5602 - val_acc: 0.8836\n",
      "Epoch 152/200\n",
      "4772/4772 [==============================] - 3s 524us/sample - loss: 0.5209 - acc: 0.8441 - val_loss: 0.4628 - val_acc: 0.8702\n",
      "Epoch 153/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.2926 - acc: 0.9011 - val_loss: 0.4775 - val_acc: 0.8693\n",
      "Epoch 154/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.2316 - acc: 0.9237 - val_loss: 0.4581 - val_acc: 0.8945\n",
      "Epoch 155/200\n",
      "4772/4772 [==============================] - 3s 550us/sample - loss: 0.1795 - acc: 0.9472 - val_loss: 0.4484 - val_acc: 0.8894\n",
      "Epoch 156/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.1631 - acc: 0.9449 - val_loss: 0.4725 - val_acc: 0.8911\n",
      "Epoch 157/200\n",
      "4772/4772 [==============================] - 3s 531us/sample - loss: 0.1565 - acc: 0.9489 - val_loss: 0.4643 - val_acc: 0.8961\n",
      "Epoch 158/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.1334 - acc: 0.9562 - val_loss: 0.5486 - val_acc: 0.8894\n",
      "Epoch 159/200\n",
      "4772/4772 [==============================] - 3s 541us/sample - loss: 0.1263 - acc: 0.9602 - val_loss: 0.4424 - val_acc: 0.9028\n",
      "Epoch 160/200\n",
      "4772/4772 [==============================] - 3s 542us/sample - loss: 0.1130 - acc: 0.9633 - val_loss: 0.4233 - val_acc: 0.9003\n",
      "Epoch 161/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.1237 - acc: 0.9604 - val_loss: 0.4840 - val_acc: 0.8936\n",
      "Epoch 162/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1375 - acc: 0.9556 - val_loss: 0.4654 - val_acc: 0.8920\n",
      "Epoch 163/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1221 - acc: 0.9600 - val_loss: 0.5221 - val_acc: 0.8685\n",
      "Epoch 164/200\n",
      "4772/4772 [==============================] - 3s 525us/sample - loss: 0.1275 - acc: 0.9577 - val_loss: 0.4459 - val_acc: 0.8953\n",
      "Epoch 165/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.1302 - acc: 0.9573 - val_loss: 0.4456 - val_acc: 0.9003\n",
      "Epoch 166/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.1226 - acc: 0.9614 - val_loss: 0.4638 - val_acc: 0.8953\n",
      "Epoch 167/200\n",
      "4772/4772 [==============================] - 3s 535us/sample - loss: 0.1203 - acc: 0.9589 - val_loss: 0.4897 - val_acc: 0.8861\n",
      "Epoch 168/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.1154 - acc: 0.9686 - val_loss: 0.4544 - val_acc: 0.9020\n",
      "Epoch 169/200\n",
      "4772/4772 [==============================] - 3s 534us/sample - loss: 0.1039 - acc: 0.9675 - val_loss: 0.4424 - val_acc: 0.9037\n",
      "Epoch 170/200\n",
      "4772/4772 [==============================] - 3s 546us/sample - loss: 0.0977 - acc: 0.9700 - val_loss: 0.4760 - val_acc: 0.8995\n",
      "Epoch 171/200\n",
      "4772/4772 [==============================] - 3s 531us/sample - loss: 0.1054 - acc: 0.9658 - val_loss: 0.4893 - val_acc: 0.8987\n",
      "Epoch 172/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1208 - acc: 0.9612 - val_loss: 0.5449 - val_acc: 0.8869\n",
      "Epoch 173/200\n",
      "4772/4772 [==============================] - 3s 541us/sample - loss: 0.1090 - acc: 0.9640 - val_loss: 0.4534 - val_acc: 0.9028\n",
      "Epoch 174/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1149 - acc: 0.9640 - val_loss: 0.4567 - val_acc: 0.8987\n",
      "Epoch 175/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1024 - acc: 0.9677 - val_loss: 0.5110 - val_acc: 0.8903\n",
      "Epoch 176/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.0959 - acc: 0.9686 - val_loss: 0.4372 - val_acc: 0.9037\n",
      "Epoch 177/200\n",
      "4772/4772 [==============================] - 3s 551us/sample - loss: 0.1075 - acc: 0.9665 - val_loss: 0.4584 - val_acc: 0.9003\n",
      "Epoch 178/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.0886 - acc: 0.9700 - val_loss: 0.4580 - val_acc: 0.9012\n",
      "Epoch 179/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.0927 - acc: 0.9675 - val_loss: 0.4964 - val_acc: 0.8953\n",
      "Epoch 180/200\n",
      "4772/4772 [==============================] - 3s 530us/sample - loss: 0.0921 - acc: 0.9690 - val_loss: 0.4707 - val_acc: 0.8995\n",
      "Epoch 181/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.0919 - acc: 0.9707 - val_loss: 0.6229 - val_acc: 0.8618\n",
      "Epoch 182/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.1224 - acc: 0.9610 - val_loss: 0.5589 - val_acc: 0.8677\n",
      "Epoch 183/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.1584 - acc: 0.9491 - val_loss: 0.4799 - val_acc: 0.8953\n",
      "Epoch 184/200\n",
      "4772/4772 [==============================] - 3s 545us/sample - loss: 0.1058 - acc: 0.9646 - val_loss: 0.4981 - val_acc: 0.8886\n",
      "Epoch 185/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.0917 - acc: 0.9717 - val_loss: 0.5073 - val_acc: 0.8920\n",
      "Epoch 186/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.1025 - acc: 0.9667 - val_loss: 0.4652 - val_acc: 0.8978\n",
      "Epoch 187/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.0975 - acc: 0.9694 - val_loss: 0.5692 - val_acc: 0.8802\n",
      "Epoch 188/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1114 - acc: 0.9633 - val_loss: 0.5729 - val_acc: 0.8827\n",
      "Epoch 189/200\n",
      "4772/4772 [==============================] - 3s 530us/sample - loss: 0.1544 - acc: 0.9489 - val_loss: 0.5102 - val_acc: 0.8970\n",
      "Epoch 190/200\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.1197 - acc: 0.9581 - val_loss: 0.5602 - val_acc: 0.8677\n",
      "Epoch 191/200\n",
      "4772/4772 [==============================] - 3s 544us/sample - loss: 0.1807 - acc: 0.9417 - val_loss: 0.5371 - val_acc: 0.8853\n",
      "Epoch 192/200\n",
      "4772/4772 [==============================] - 3s 533us/sample - loss: 0.1128 - acc: 0.9617 - val_loss: 0.5010 - val_acc: 0.8894\n",
      "Epoch 193/200\n",
      "4772/4772 [==============================] - 3s 538us/sample - loss: 0.1033 - acc: 0.9669 - val_loss: 0.4764 - val_acc: 0.9020\n",
      "Epoch 194/200\n",
      "4772/4772 [==============================] - 3s 536us/sample - loss: 0.1058 - acc: 0.9652 - val_loss: 0.5169 - val_acc: 0.8903\n",
      "Epoch 195/200\n",
      "4772/4772 [==============================] - 3s 543us/sample - loss: 0.0952 - acc: 0.9673 - val_loss: 0.4514 - val_acc: 0.8978\n",
      "Epoch 196/200\n",
      "4772/4772 [==============================] - 3s 527us/sample - loss: 0.0983 - acc: 0.9663 - val_loss: 0.4857 - val_acc: 0.8894\n",
      "Epoch 197/200\n",
      "4772/4772 [==============================] - 3s 548us/sample - loss: 0.1087 - acc: 0.9640 - val_loss: 0.5155 - val_acc: 0.8911\n",
      "Epoch 198/200\n",
      "4772/4772 [==============================] - 3s 539us/sample - loss: 0.0924 - acc: 0.9725 - val_loss: 0.5123 - val_acc: 0.8953\n",
      "Epoch 199/200\n",
      "4772/4772 [==============================] - 3s 540us/sample - loss: 0.1088 - acc: 0.9652 - val_loss: 0.4835 - val_acc: 0.8853\n",
      "Epoch 200/200\n",
      "4772/4772 [==============================] - 3s 529us/sample - loss: 0.0808 - acc: 0.9738 - val_loss: 0.5193 - val_acc: 0.8911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test))\n",
    "\n",
    "val_acc=history.history['val_acc']\n",
    "acc=history.history['acc']\n",
    "\n",
    "plt.plot(val_acc)\n",
    "plt.plot(acc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marcpozzo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tf_model') \n",
    "#new_model = tf.keras.models.load_model('model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4772 samples, validate on 1194 samples\n",
      "Epoch 1/3\n",
      "4772/4772 [==============================] - 3s 730us/sample - loss: 1.2703 - acc: 0.5953 - val_loss: 1.1944 - val_acc: 0.5913\n",
      "Epoch 2/3\n",
      "4772/4772 [==============================] - 3s 586us/sample - loss: 0.8039 - acc: 0.7513 - val_loss: 0.7747 - val_acc: 0.7437\n",
      "Epoch 3/3\n",
      "4772/4772 [==============================] - 3s 537us/sample - loss: 0.7599 - acc: 0.7554 - val_loss: 0.8747 - val_acc: 0.6499\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history\n",
    "#Pour 0.1 d epochs\n",
    "#A partir de 170 epochs overfit\n",
    "#Sinon stabil vers 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       723\n",
      "           1       0.59      0.94      0.73        17\n",
      "           2       0.88      0.88      0.88       216\n",
      "           3       0.58      0.85      0.69        46\n",
      "           4       0.63      0.61      0.62        36\n",
      "           5       0.87      0.93      0.90       156\n",
      "\n",
      "    accuracy                           0.90      1194\n",
      "   macro avg       0.75      0.85      0.79      1194\n",
      "weighted avg       0.91      0.90      0.90      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      2778\n",
      "           1       0.99      0.99      0.99       109\n",
      "           2       0.98      1.00      0.99       847\n",
      "           3       0.97      1.00      0.98       262\n",
      "           4       0.99      1.00      0.99       140\n",
      "           5       0.95      0.99      0.97       636\n",
      "\n",
      "    accuracy                           0.99      4772\n",
      "   macro avg       0.98      0.99      0.99      4772\n",
      "weighted avg       0.99      0.99      0.99      4772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(x_train).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
