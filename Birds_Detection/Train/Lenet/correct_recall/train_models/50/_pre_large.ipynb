{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un problème de vp ???\n",
    "#image_2019-06-15_10-47-26_1112_64_2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'abord vérifier si on a du Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing \n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.2\n",
    "\n",
    "\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.3\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcpozzo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_path=\"/mnt/VegaSlowDataDisk/c3po_interface/bin/fp_images/\"\n",
    "\n",
    "\n",
    "\n",
    "fp_new=pd.read_csv(\"/mnt/VegaSlowDataDisk/c3po_interface/bin/fp_threshold/table_fp_new.csv\")\n",
    "\n",
    "liste_img_paths=[]\n",
    "for i in range(len(fp_new)):\n",
    "    liste_img_paths.append(n_path+fp_new[\"imagetteName\"].iloc[i])\n",
    "\n",
    "fp_new[\"img_paths\"]=liste_img_paths\n",
    "#imagetteNamefp_new.head()\n",
    "\n",
    "fp_new[\"class\"]=\"autre\"\n",
    "fp_new.columns\n",
    "\n",
    "to_drop=['path', 'filename', 'imagetteName', 'max_cat', 'cat', 'xmin', 'xmax','ymin', 'ymax', 'former_index']\n",
    "\n",
    "fp_new.drop(to_drop,axis=1,inplace=True)\n",
    "\n",
    "df=pd.concat([df,fp_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40827 validated image filenames belonging to 6 classes.\n",
      "Found 10207 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input\n",
    "        # data augmentation\n",
    "        #rotation_range = 10,\n",
    "        #zoom_range = zoom_range,\n",
    "        #horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    #preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_train) )\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_test))\n",
    "\n",
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 39s 945us/sample - loss: 0.3632 - acc: 0.9039 - val_loss: 0.1449 - val_acc: 0.9636\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 37s 903us/sample - loss: 0.1359 - acc: 0.9638 - val_loss: 0.0991 - val_acc: 0.9739\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 37s 903us/sample - loss: 0.1107 - acc: 0.9696 - val_loss: 0.1126 - val_acc: 0.9677\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 35s 869us/sample - loss: 0.0933 - acc: 0.9733 - val_loss: 0.0751 - val_acc: 0.9786\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 37s 911us/sample - loss: 0.0842 - acc: 0.9750 - val_loss: 0.0720 - val_acc: 0.9789\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 41s 1ms/sample - loss: 0.0726 - acc: 0.9787 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0642 - acc: 0.9803 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0605 - acc: 0.9807 - val_loss: 0.0573 - val_acc: 0.9842\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0547 - acc: 0.9827 - val_loss: 0.0675 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0502 - acc: 0.9845 - val_loss: 0.0584 - val_acc: 0.9839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99629   0.98854   0.99240      9773\n",
      "           1    0.62963   1.00000   0.77273        17\n",
      "           2    0.82326   0.91237   0.86553       194\n",
      "           3    0.67164   0.70312   0.68702        64\n",
      "           4    0.48571   0.89474   0.62963        19\n",
      "           5    0.75904   0.90000   0.82353       140\n",
      "\n",
      "    accuracy                        0.98393     10207\n",
      "   macro avg    0.72759   0.89980   0.79514     10207\n",
      "weighted avg    0.98615   0.98393   0.98472     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0424 - acc: 0.9864 - val_loss: 0.0653 - val_acc: 0.9811\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0393 - acc: 0.9875 - val_loss: 0.0585 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0381 - acc: 0.9876 - val_loss: 0.0601 - val_acc: 0.9825\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0331 - acc: 0.9892 - val_loss: 0.0590 - val_acc: 0.9849\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0608 - val_acc: 0.9841\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0597 - val_acc: 0.9847\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0589 - val_acc: 0.9842\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0615 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0234 - acc: 0.9919 - val_loss: 0.0644 - val_acc: 0.9842\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0644 - val_acc: 0.9842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99453   0.99075   0.99264      9734\n",
      "           1    0.66667   0.90000   0.76596        20\n",
      "           2    0.86047   0.86449   0.86247       214\n",
      "           3    0.67164   0.78947   0.72581        57\n",
      "           4    0.62857   0.70968   0.66667        31\n",
      "           5    0.79518   0.87417   0.83281       151\n",
      "\n",
      "    accuracy                        0.98423     10207\n",
      "   macro avg    0.76951   0.85476   0.80772     10207\n",
      "weighted avg    0.98522   0.98423   0.98462     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0676 - val_acc: 0.9833\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0749 - val_acc: 0.9851\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0634 - val_acc: 0.9852\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0690 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0757 - val_acc: 0.9835\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0682 - val_acc: 0.9843\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 43s 1ms/sample - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0728 - val_acc: 0.9854\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0784 - val_acc: 0.9845\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0671 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0829 - val_acc: 0.9852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99464   0.99167   0.99315      9726\n",
      "           1    0.77778   0.91304   0.84000        23\n",
      "           2    0.88837   0.81974   0.85268       233\n",
      "           3    0.59701   0.97561   0.74074        41\n",
      "           4    0.54286   0.90476   0.67857        21\n",
      "           5    0.84337   0.85890   0.85106       163\n",
      "\n",
      "    accuracy                        0.98521     10207\n",
      "   macro avg    0.77401   0.91062   0.82603     10207\n",
      "weighted avg    0.98678   0.98521   0.98567     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0721 - val_acc: 0.9850\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 43s 1ms/sample - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0721 - val_acc: 0.9863\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0735 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0876 - val_acc: 0.9841\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0081 - acc: 0.9971 - val_loss: 0.0803 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0097 - acc: 0.9965 - val_loss: 0.0841 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0898 - val_acc: 0.9827\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 44s 1ms/sample - loss: 0.0077 - acc: 0.9971 - val_loss: 0.0809 - val_acc: 0.9860\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0802 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0846 - val_acc: 0.9846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99361   0.99238   0.99299      9709\n",
      "           1    0.74074   0.80000   0.76923        25\n",
      "           2    0.88372   0.85202   0.86758       223\n",
      "           3    0.68657   0.86792   0.76667        53\n",
      "           4    0.57143   0.80000   0.66667        25\n",
      "           5    0.83735   0.80814   0.82249       172\n",
      "\n",
      "    accuracy                        0.98462     10207\n",
      "   macro avg    0.78557   0.85341   0.81427     10207\n",
      "weighted avg    0.98532   0.98462   0.98486     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0863 - val_acc: 0.9862\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0877 - val_acc: 0.9854\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0918 - val_acc: 0.9851\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0062 - acc: 0.9978 - val_loss: 0.1032 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0809 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0825 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0934 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0058 - acc: 0.9977 - val_loss: 0.0881 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0909 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0970 - val_acc: 0.9853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99536   0.99117   0.99326      9738\n",
      "           1    0.81481   0.91667   0.86275        24\n",
      "           2    0.87907   0.86301   0.87097       219\n",
      "           3    0.64179   0.82692   0.72269        52\n",
      "           4    0.60000   0.67742   0.63636        31\n",
      "           5    0.78313   0.90909   0.84142       143\n",
      "\n",
      "    accuracy                        0.98530     10207\n",
      "   macro avg    0.78569   0.86405   0.82124     10207\n",
      "weighted avg    0.98646   0.98530   0.98574     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 46s 1ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1012 - val_acc: 0.9857\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0958 - val_acc: 0.9852\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0946 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0068 - acc: 0.9978 - val_loss: 0.1063 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 45s 1ms/sample - loss: 0.0058 - acc: 0.9979 - val_loss: 0.1022 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "26976/40827 [==================>...........] - ETA: 14s - loss: 0.0053 - acc: 0.9984"
     ]
    }
   ],
   "source": [
    "val_acc=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "loss=[]\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "val_acc_liste\n",
    "acc_liste\n",
    "\n",
    "\n",
    "val_acc_liste = list(itertools.chain(*val_acc))\n",
    "acc_liste = list(itertools.chain(*acc))\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.plot(acc_liste,label=\"train\");\n",
    "plt.plot(val_acc_liste,label=\"test\");\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy en fonction du nombre d'epoch\");\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loss_liste = list(itertools.chain(*val_loss))\n",
    "loss_liste = list(itertools.chain(*loss))\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.plot(loss_liste,label=\"train\");\n",
    "plt.plot(val_loss_liste,label=\"test\");\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy en fonction du nombre d'epoch\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#99238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 30s 731us/sample - loss: 0.3632 - acc: 0.9039 - val_loss: 0.1449 - val_acc: 0.9636\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 28s 692us/sample - loss: 0.1359 - acc: 0.9638 - val_loss: 0.0991 - val_acc: 0.9739\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 28s 697us/sample - loss: 0.1107 - acc: 0.9696 - val_loss: 0.1126 - val_acc: 0.9677\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 28s 696us/sample - loss: 0.0933 - acc: 0.9733 - val_loss: 0.0751 - val_acc: 0.9786\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 28s 697us/sample - loss: 0.0842 - acc: 0.9750 - val_loss: 0.0720 - val_acc: 0.9789\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 28s 697us/sample - loss: 0.0726 - acc: 0.9787 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 28s 698us/sample - loss: 0.0642 - acc: 0.9803 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 28s 697us/sample - loss: 0.0605 - acc: 0.9807 - val_loss: 0.0573 - val_acc: 0.9842\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 28s 698us/sample - loss: 0.0547 - acc: 0.9827 - val_loss: 0.0675 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 28s 676us/sample - loss: 0.0502 - acc: 0.9845 - val_loss: 0.0584 - val_acc: 0.9839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99629   0.98854   0.99240      9773\n",
      "           1    0.62963   1.00000   0.77273        17\n",
      "           2    0.82326   0.91237   0.86553       194\n",
      "           3    0.67164   0.70312   0.68702        64\n",
      "           4    0.48571   0.89474   0.62963        19\n",
      "           5    0.75904   0.90000   0.82353       140\n",
      "\n",
      "    accuracy                        0.98393     10207\n",
      "   macro avg    0.72759   0.89980   0.79514     10207\n",
      "weighted avg    0.98615   0.98393   0.98472     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 30s 729us/sample - loss: 0.0424 - acc: 0.9864 - val_loss: 0.0653 - val_acc: 0.9811\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 31s 750us/sample - loss: 0.0393 - acc: 0.9875 - val_loss: 0.0585 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 31s 762us/sample - loss: 0.0381 - acc: 0.9876 - val_loss: 0.0601 - val_acc: 0.9825\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 30s 734us/sample - loss: 0.0331 - acc: 0.9892 - val_loss: 0.0590 - val_acc: 0.9849\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0608 - val_acc: 0.9841\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0597 - val_acc: 0.9847\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 705us/sample - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0589 - val_acc: 0.9842\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 28s 697us/sample - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0615 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 698us/sample - loss: 0.0234 - acc: 0.9919 - val_loss: 0.0644 - val_acc: 0.9842\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 701us/sample - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0644 - val_acc: 0.9842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99453   0.99075   0.99264      9734\n",
      "           1    0.66667   0.90000   0.76596        20\n",
      "           2    0.86047   0.86449   0.86247       214\n",
      "           3    0.67164   0.78947   0.72581        57\n",
      "           4    0.62857   0.70968   0.66667        31\n",
      "           5    0.79518   0.87417   0.83281       151\n",
      "\n",
      "    accuracy                        0.98423     10207\n",
      "   macro avg    0.76951   0.85476   0.80772     10207\n",
      "weighted avg    0.98522   0.98423   0.98462     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 711us/sample - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0676 - val_acc: 0.9833\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0749 - val_acc: 0.9851\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0634 - val_acc: 0.9852\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 29s 704us/sample - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0690 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 710us/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0757 - val_acc: 0.9835\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 713us/sample - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0682 - val_acc: 0.9843\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 28s 695us/sample - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0728 - val_acc: 0.9854\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 28s 694us/sample - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0784 - val_acc: 0.9845\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 705us/sample - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0671 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 30s 727us/sample - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0829 - val_acc: 0.9852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99464   0.99167   0.99315      9726\n",
      "           1    0.77778   0.91304   0.84000        23\n",
      "           2    0.88837   0.81974   0.85268       233\n",
      "           3    0.59701   0.97561   0.74074        41\n",
      "           4    0.54286   0.90476   0.67857        21\n",
      "           5    0.84337   0.85890   0.85106       163\n",
      "\n",
      "    accuracy                        0.98521     10207\n",
      "   macro avg    0.77401   0.91062   0.82603     10207\n",
      "weighted avg    0.98678   0.98521   0.98567     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 30s 727us/sample - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0721 - val_acc: 0.9850\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 710us/sample - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0721 - val_acc: 0.9863\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 718us/sample - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0735 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 30s 724us/sample - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0876 - val_acc: 0.9841\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0081 - acc: 0.9971 - val_loss: 0.0803 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 705us/sample - loss: 0.0097 - acc: 0.9965 - val_loss: 0.0841 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 702us/sample - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0898 - val_acc: 0.9827\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0077 - acc: 0.9971 - val_loss: 0.0809 - val_acc: 0.9860\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 28s 694us/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0802 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 30s 724us/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0846 - val_acc: 0.9846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99361   0.99238   0.99299      9709\n",
      "           1    0.74074   0.80000   0.76923        25\n",
      "           2    0.88372   0.85202   0.86758       223\n",
      "           3    0.68657   0.86792   0.76667        53\n",
      "           4    0.57143   0.80000   0.66667        25\n",
      "           5    0.83735   0.80814   0.82249       172\n",
      "\n",
      "    accuracy                        0.98462     10207\n",
      "   macro avg    0.78557   0.85341   0.81427     10207\n",
      "weighted avg    0.98532   0.98462   0.98486     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 30s 728us/sample - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0863 - val_acc: 0.9862\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 30s 730us/sample - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0877 - val_acc: 0.9854\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0918 - val_acc: 0.9851\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 29s 718us/sample - loss: 0.0062 - acc: 0.9978 - val_loss: 0.1032 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 723us/sample - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0809 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 30s 723us/sample - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0825 - val_acc: 0.9849\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0934 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0058 - acc: 0.9977 - val_loss: 0.0881 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 30s 744us/sample - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0909 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 710us/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0970 - val_acc: 0.9853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99536   0.99117   0.99326      9738\n",
      "           1    0.81481   0.91667   0.86275        24\n",
      "           2    0.87907   0.86301   0.87097       219\n",
      "           3    0.64179   0.82692   0.72269        52\n",
      "           4    0.60000   0.67742   0.63636        31\n",
      "           5    0.78313   0.90909   0.84142       143\n",
      "\n",
      "    accuracy                        0.98530     10207\n",
      "   macro avg    0.78569   0.86405   0.82124     10207\n",
      "weighted avg    0.98646   0.98530   0.98574     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1012 - val_acc: 0.9857\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 720us/sample - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0958 - val_acc: 0.9852\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 30s 734us/sample - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0946 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 29s 705us/sample - loss: 0.0068 - acc: 0.9978 - val_loss: 0.1063 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 30s 747us/sample - loss: 0.0058 - acc: 0.9979 - val_loss: 0.1022 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 722us/sample - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0810 - val_acc: 0.9866\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0994 - val_acc: 0.9853\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 30s 723us/sample - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0959 - val_acc: 0.9868\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 31s 750us/sample - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0906 - val_acc: 0.9858\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 722us/sample - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0873 - val_acc: 0.9866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99526   0.99178   0.99351      9731\n",
      "           1    0.74074   0.95238   0.83333        21\n",
      "           2    0.90233   0.85463   0.87783       227\n",
      "           3    0.68657   0.90196   0.77966        51\n",
      "           4    0.62857   0.88000   0.73333        25\n",
      "           5    0.82530   0.90132   0.86164       152\n",
      "\n",
      "    accuracy                        0.98658     10207\n",
      "   macro avg    0.79646   0.91368   0.84655     10207\n",
      "weighted avg    0.98769   0.98658   0.98694     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 717us/sample - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0912 - val_acc: 0.9866\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 720us/sample - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0937 - val_acc: 0.9868\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 705us/sample - loss: 0.0044 - acc: 0.9985 - val_loss: 0.1123 - val_acc: 0.9859\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 29s 713us/sample - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0965 - val_acc: 0.9851\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 712us/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 0.1001 - val_acc: 0.9866\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 701us/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0866 - val_acc: 0.9871\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 30s 726us/sample - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0910 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 29s 703us/sample - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0972 - val_acc: 0.9861\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 711us/sample - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0999 - val_acc: 0.9862\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 28s 696us/sample - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1054 - val_acc: 0.9862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99649   0.99098   0.99373      9751\n",
      "           1    0.55556   0.78947   0.65217        19\n",
      "           2    0.88372   0.88785   0.88578       214\n",
      "           3    0.64179   0.91489   0.75439        47\n",
      "           4    0.51429   0.94737   0.66667        19\n",
      "           5    0.82530   0.87261   0.84830       157\n",
      "\n",
      "    accuracy                        0.98619     10207\n",
      "   macro avg    0.73619   0.90053   0.80017     10207\n",
      "weighted avg    0.98814   0.98619   0.98688     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 707us/sample - loss: 0.0048 - acc: 0.9983 - val_loss: 0.1180 - val_acc: 0.9866\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 713us/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1090 - val_acc: 0.9857\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 716us/sample - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1131 - val_acc: 0.9849\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 30s 738us/sample - loss: 0.0035 - acc: 0.9988 - val_loss: 0.1111 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 701us/sample - loss: 0.0031 - acc: 0.9989 - val_loss: 0.1246 - val_acc: 0.9866\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 30s 724us/sample - loss: 0.0035 - acc: 0.9988 - val_loss: 0.1073 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 712us/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 0.1190 - val_acc: 0.9842\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0046 - acc: 0.9985 - val_loss: 0.1072 - val_acc: 0.9867\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 713us/sample - loss: 0.0032 - acc: 0.9989 - val_loss: 0.1202 - val_acc: 0.9851\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 711us/sample - loss: 0.0074 - acc: 0.9978 - val_loss: 0.1099 - val_acc: 0.9862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99639   0.99087   0.99362      9751\n",
      "           1    0.81481   1.00000   0.89796        22\n",
      "           2    0.86047   0.88942   0.87470       208\n",
      "           3    0.64179   0.82692   0.72269        52\n",
      "           4    0.54286   0.86364   0.66667        22\n",
      "           5    0.81325   0.88816   0.84906       152\n",
      "\n",
      "    accuracy                        0.98619     10207\n",
      "   macro avg    0.77826   0.90984   0.83412     10207\n",
      "weighted avg    0.98772   0.98619   0.98676     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 31s 750us/sample - loss: 0.0025 - acc: 0.9990 - val_loss: 0.1110 - val_acc: 0.9856\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 720us/sample - loss: 0.0043 - acc: 0.9985 - val_loss: 0.1155 - val_acc: 0.9874\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 704us/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1074 - val_acc: 0.9861\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 30s 728us/sample - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1065 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 30s 727us/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1256 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 30s 743us/sample - loss: 0.0044 - acc: 0.9986 - val_loss: 0.1142 - val_acc: 0.9865\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 715us/sample - loss: 0.0039 - acc: 0.9989 - val_loss: 0.1225 - val_acc: 0.9858\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 29s 716us/sample - loss: 0.0032 - acc: 0.9988 - val_loss: 0.1148 - val_acc: 0.9851\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 712us/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 0.1081 - val_acc: 0.9860\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 703us/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1222 - val_acc: 0.9856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99670   0.98946   0.99306      9768\n",
      "           1    0.74074   0.90909   0.81633        22\n",
      "           2    0.82326   0.89848   0.85922       197\n",
      "           3    0.64179   0.86000   0.73504        50\n",
      "           4    0.60000   1.00000   0.75000        21\n",
      "           5    0.80723   0.89933   0.85079       149\n",
      "\n",
      "    accuracy                        0.98560     10207\n",
      "   macro avg    0.76829   0.92606   0.83408     10207\n",
      "weighted avg    0.98748   0.98560   0.98626     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 0.1228 - val_acc: 0.9851\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 30s 734us/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1244 - val_acc: 0.9856\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 30s 743us/sample - loss: 0.0037 - acc: 0.9988 - val_loss: 0.1224 - val_acc: 0.9855\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 31s 752us/sample - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1168 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 711us/sample - loss: 0.0033 - acc: 0.9989 - val_loss: 0.1091 - val_acc: 0.9865\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 712us/sample - loss: 0.0026 - acc: 0.9990 - val_loss: 0.1129 - val_acc: 0.9859\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 29s 710us/sample - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1195 - val_acc: 0.9863\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 30s 728us/sample - loss: 0.0024 - acc: 0.9992 - val_loss: 0.1045 - val_acc: 0.9880\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 29s 702us/sample - loss: 0.0035 - acc: 0.9989 - val_loss: 0.1193 - val_acc: 0.9863\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 30s 734us/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1116 - val_acc: 0.9867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99670   0.99037   0.99352      9759\n",
      "           1    0.77778   0.84000   0.80769        25\n",
      "           2    0.83721   0.90452   0.86957       199\n",
      "           3    0.70149   0.90385   0.78992        52\n",
      "           4    0.60000   0.91304   0.72414        23\n",
      "           5    0.82530   0.91946   0.86984       149\n",
      "\n",
      "    accuracy                        0.98668     10207\n",
      "   macro avg    0.78975   0.91187   0.84245     10207\n",
      "weighted avg    0.98815   0.98668   0.98720     10207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_acc=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "loss=[]\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "val_acc_liste = list(itertools.chain(*val_acc))\n",
    "acc_liste = list(itertools.chain(*acc))\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.plot(acc_liste,label=\"train\");\n",
    "plt.plot(val_acc_liste,label=\"test\");\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy en fonction du nombre d'epoch\");\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autour de  0.99238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/35\n",
      "40827/40827 [==============================] - 30s 735us/sample - loss: 0.3632 - acc: 0.9039 - val_loss: 0.1449 - val_acc: 0.9636\n",
      "Epoch 2/35\n",
      "40827/40827 [==============================] - 28s 690us/sample - loss: 0.1359 - acc: 0.9638 - val_loss: 0.0991 - val_acc: 0.9739\n",
      "Epoch 3/35\n",
      "40827/40827 [==============================] - 29s 716us/sample - loss: 0.1107 - acc: 0.9696 - val_loss: 0.1126 - val_acc: 0.9677\n",
      "Epoch 4/35\n",
      "40827/40827 [==============================] - 30s 740us/sample - loss: 0.0933 - acc: 0.9733 - val_loss: 0.0751 - val_acc: 0.9786\n",
      "Epoch 5/35\n",
      "40827/40827 [==============================] - 28s 694us/sample - loss: 0.0842 - acc: 0.9750 - val_loss: 0.0720 - val_acc: 0.9789\n",
      "Epoch 6/35\n",
      "40827/40827 [==============================] - 28s 690us/sample - loss: 0.0726 - acc: 0.9787 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 7/35\n",
      "40827/40827 [==============================] - 28s 685us/sample - loss: 0.0642 - acc: 0.9803 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 8/35\n",
      "40827/40827 [==============================] - 28s 692us/sample - loss: 0.0605 - acc: 0.9807 - val_loss: 0.0573 - val_acc: 0.9842\n",
      "Epoch 9/35\n",
      "40827/40827 [==============================] - 29s 714us/sample - loss: 0.0547 - acc: 0.9827 - val_loss: 0.0675 - val_acc: 0.9810\n",
      "Epoch 10/35\n",
      "40827/40827 [==============================] - 29s 700us/sample - loss: 0.0502 - acc: 0.9845 - val_loss: 0.0584 - val_acc: 0.9839\n",
      "Epoch 11/35\n",
      "40827/40827 [==============================] - 28s 685us/sample - loss: 0.0430 - acc: 0.9869 - val_loss: 0.0633 - val_acc: 0.9813\n",
      "Epoch 12/35\n",
      "40827/40827 [==============================] - 28s 696us/sample - loss: 0.0395 - acc: 0.9878 - val_loss: 0.0645 - val_acc: 0.9818\n",
      "Epoch 13/35\n",
      "40827/40827 [==============================] - 29s 716us/sample - loss: 0.0345 - acc: 0.9887 - val_loss: 0.0557 - val_acc: 0.9837\n",
      "Epoch 14/35\n",
      "40827/40827 [==============================] - 28s 696us/sample - loss: 0.0332 - acc: 0.9895 - val_loss: 0.0678 - val_acc: 0.9824\n",
      "Epoch 15/35\n",
      "40827/40827 [==============================] - 29s 722us/sample - loss: 0.0297 - acc: 0.9907 - val_loss: 0.0618 - val_acc: 0.9844\n",
      "Epoch 16/35\n",
      "40827/40827 [==============================] - 28s 695us/sample - loss: 0.0301 - acc: 0.9901 - val_loss: 0.0653 - val_acc: 0.9846\n",
      "Epoch 17/35\n",
      "40827/40827 [==============================] - 29s 706us/sample - loss: 0.0267 - acc: 0.9911 - val_loss: 0.0710 - val_acc: 0.9835\n",
      "Epoch 18/35\n",
      "40827/40827 [==============================] - 28s 691us/sample - loss: 0.0240 - acc: 0.9915 - val_loss: 0.0643 - val_acc: 0.9846\n",
      "Epoch 19/35\n",
      "40827/40827 [==============================] - 29s 700us/sample - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0620 - val_acc: 0.9846\n",
      "Epoch 20/35\n",
      "40827/40827 [==============================] - 29s 699us/sample - loss: 0.0206 - acc: 0.9929 - val_loss: 0.0671 - val_acc: 0.9844\n",
      "Epoch 21/35\n",
      "40827/40827 [==============================] - 29s 703us/sample - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0692 - val_acc: 0.9860\n",
      "Epoch 22/35\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0190 - acc: 0.9933 - val_loss: 0.0704 - val_acc: 0.9850\n",
      "Epoch 23/35\n",
      "40827/40827 [==============================] - 30s 724us/sample - loss: 0.0187 - acc: 0.9936 - val_loss: 0.0626 - val_acc: 0.9860\n",
      "Epoch 24/35\n",
      "40827/40827 [==============================] - 28s 696us/sample - loss: 0.0169 - acc: 0.9945 - val_loss: 0.0622 - val_acc: 0.9856\n",
      "Epoch 25/35\n",
      "40827/40827 [==============================] - 29s 706us/sample - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0671 - val_acc: 0.9855\n",
      "Epoch 26/35\n",
      "40827/40827 [==============================] - 29s 710us/sample - loss: 0.0168 - acc: 0.9942 - val_loss: 0.0646 - val_acc: 0.9857\n",
      "Epoch 27/35\n",
      "40827/40827 [==============================] - 29s 706us/sample - loss: 0.0159 - acc: 0.9952 - val_loss: 0.0687 - val_acc: 0.9853\n",
      "Epoch 28/35\n",
      "40827/40827 [==============================] - 29s 714us/sample - loss: 0.0142 - acc: 0.9946 - val_loss: 0.0719 - val_acc: 0.9852\n",
      "Epoch 29/35\n",
      "40827/40827 [==============================] - 29s 709us/sample - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0665 - val_acc: 0.9852\n",
      "Epoch 30/35\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0693 - val_acc: 0.9863\n",
      "Epoch 31/35\n",
      "40827/40827 [==============================] - 29s 700us/sample - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0664 - val_acc: 0.9862\n",
      "Epoch 32/35\n",
      "40827/40827 [==============================] - 28s 684us/sample - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0705 - val_acc: 0.9851\n",
      "Epoch 33/35\n",
      "40827/40827 [==============================] - 29s 700us/sample - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0643 - val_acc: 0.9868\n",
      "Epoch 34/35\n",
      "40827/40827 [==============================] - 28s 677us/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0611 - val_acc: 0.9870\n",
      "Epoch 35/35\n",
      "40827/40827 [==============================] - 28s 692us/sample - loss: 0.0103 - acc: 0.9963 - val_loss: 0.0663 - val_acc: 0.9867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99526   0.99178   0.99351      9731\n",
      "           1    0.81481   1.00000   0.89796        22\n",
      "           2    0.87442   0.89100   0.88263       211\n",
      "           3    0.74627   0.83333   0.78740        60\n",
      "           4    0.65714   0.85185   0.74194        27\n",
      "           5    0.82530   0.87821   0.85093       156\n",
      "\n",
      "    accuracy                        0.98668     10207\n",
      "   macro avg    0.81887   0.90769   0.85906     10207\n",
      "weighted avg    0.98741   0.98668   0.98696     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99412   0.98973   0.99192      9740\n",
      "           1    0.51852   1.00000   0.68293        14\n",
      "           2    0.84651   0.87081   0.85849       209\n",
      "           3    0.76119   0.78462   0.77273        65\n",
      "           4    0.65714   0.52273   0.58228        44\n",
      "           5    0.71687   0.88148   0.79070       135\n",
      "\n",
      "    accuracy                        0.98256     10207\n",
      "   macro avg    0.74906   0.84156   0.77984     10207\n",
      "weighted avg    0.98384   0.98256   0.98294     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99722   0.98875   0.99297      9780\n",
      "           1    0.85185   0.95833   0.90196        24\n",
      "           2    0.88372   0.90047   0.89202       211\n",
      "           3    0.62687   0.95455   0.75676        44\n",
      "           4    0.65714   0.82143   0.73016        28\n",
      "           5    0.66265   0.91667   0.76923       120\n",
      "\n",
      "    accuracy                        0.98540     10207\n",
      "   macro avg    0.77991   0.92337   0.84052     10207\n",
      "weighted avg    0.98806   0.98540   0.98630     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99402   0.99167   0.99284      9720\n",
      "           1    0.77778   1.00000   0.87500        21\n",
      "           2    0.88372   0.81197   0.84633       234\n",
      "           3    0.56716   0.79167   0.66087        48\n",
      "           4    0.60000   0.77778   0.67742        27\n",
      "           5    0.81325   0.85987   0.83591       157\n",
      "\n",
      "    accuracy                        0.98403     10207\n",
      "   macro avg    0.77266   0.87216   0.81473     10207\n",
      "weighted avg    0.98522   0.98403   0.98443     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99309   0.99237   0.99273      9704\n",
      "           1    0.81481   0.84615   0.83019        26\n",
      "           2    0.86977   0.87383   0.87179       214\n",
      "           3    0.71642   0.84211   0.77419        57\n",
      "           4    0.62857   0.78571   0.69841        28\n",
      "           5    0.85542   0.79775   0.82558       178\n",
      "\n",
      "    accuracy                        0.98472     10207\n",
      "   macro avg    0.81301   0.85632   0.83215     10207\n",
      "weighted avg    0.98511   0.98472   0.98484     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99505   0.98913   0.99208      9755\n",
      "           1    0.81481   0.81481   0.81481        27\n",
      "           2    0.86512   0.87324   0.86916       213\n",
      "           3    0.62687   0.80769   0.70588        52\n",
      "           4    0.60000   0.77778   0.67742        27\n",
      "           5    0.72892   0.90977   0.80936       133\n",
      "\n",
      "    accuracy                        0.98374     10207\n",
      "   macro avg    0.77179   0.86207   0.81145     10207\n",
      "weighted avg    0.98547   0.98374   0.98438     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99618   0.98996   0.99306      9758\n",
      "           1    0.66667   1.00000   0.80000        18\n",
      "           2    0.86512   0.90291   0.88361       206\n",
      "           3    0.67164   0.78947   0.72581        57\n",
      "           4    0.51429   0.94737   0.66667        19\n",
      "           5    0.78313   0.87248   0.82540       149\n",
      "\n",
      "    accuracy                        0.98530     10207\n",
      "   macro avg    0.74950   0.91703   0.81576     10207\n",
      "weighted avg    0.98714   0.98530   0.98596     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99567   0.99005   0.99285      9752\n",
      "           1    0.81481   0.84615   0.83019        26\n",
      "           2    0.85116   0.89268   0.87143       205\n",
      "           3    0.64179   0.89583   0.74783        48\n",
      "           4    0.48571   0.70833   0.57627        24\n",
      "           5    0.76506   0.83553   0.79874       152\n",
      "\n",
      "    accuracy                        0.98432     10207\n",
      "   macro avg    0.75904   0.86143   0.80288     10207\n",
      "weighted avg    0.98601   0.98432   0.98498     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99670   0.99159   0.99414      9747\n",
      "           1    0.74074   0.95238   0.83333        21\n",
      "           2    0.82326   0.92670   0.87192       191\n",
      "           3    0.74627   0.84746   0.79365        59\n",
      "           4    0.65714   0.74194   0.69697        31\n",
      "           5    0.83133   0.87342   0.85185       158\n",
      "\n",
      "    accuracy                        0.98687     10207\n",
      "   macro avg    0.79924   0.88891   0.84031     10207\n",
      "weighted avg    0.98789   0.98687   0.98726     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99433   0.99014   0.99223      9738\n",
      "           1    0.77778   0.84000   0.80769        25\n",
      "           2    0.86977   0.85000   0.85977       220\n",
      "           3    0.67164   0.81818   0.73770        55\n",
      "           4    0.62857   0.73333   0.67692        30\n",
      "           5    0.74699   0.89209   0.81311       139\n",
      "\n",
      "    accuracy                        0.98374     10207\n",
      "   macro avg    0.78151   0.85396   0.81457     10207\n",
      "weighted avg    0.98493   0.98374   0.98419     10207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99670   0.99016   0.99342      9761\n",
      "           1    0.74074   0.90909   0.81633        22\n",
      "           2    0.86047   0.88942   0.87470       208\n",
      "           3    0.73134   0.81667   0.77165        60\n",
      "           4    0.57143   0.95238   0.71429        21\n",
      "           5    0.78916   0.97037   0.87043       135\n",
      "\n",
      "    accuracy                        0.98658     10207\n",
      "   macro avg    0.78164   0.92135   0.84014     10207\n",
      "weighted avg    0.98819   0.98658   0.98712     10207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=35,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
