{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'abord vérifier si on a du Lenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essayons de faire lenet avec tf voir ci-dessous . Il y a aussi une commande pour voir le résumer peut être .resume\n",
    "def build_model(width, height, depth, classes,drop_out_rate):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(30, (5, 5), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(128),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(drop_out_rate),\n",
    "        \n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_2.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_3.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0258_pigeon_4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0335_pigeon_8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0341_pigeon_10.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                            img_paths\n",
       "2   corneille  Rec_images/DSCF0180_corneille_2.JPG\n",
       "3   corneille  Rec_images/DSCF0180_corneille_3.JPG\n",
       "4      pigeon     Rec_images/DSCF0258_pigeon_4.JPG\n",
       "8      pigeon     Rec_images/DSCF0335_pigeon_8.JPG\n",
       "10     pigeon    Rec_images/DSCF0341_pigeon_10.JPG"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(\"/home/marcpozzo/Desktop/c3po/Images_aquises/generateur.csv\")\n",
    "df=df[(df[\"class\"]=='corneille') | (df[\"class\"]=='pigeon') | (df[\"class\"]=='faisan')   ]\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.2\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.3\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>autre</td>\n",
       "      <td>/home/marcpozzo/Desktop/c3po/Images_aquises/Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>corneille</td>\n",
       "      <td>/home/marcpozzo/Desktop/c3po/Images_aquises/Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>corneille</td>\n",
       "      <td>/home/marcpozzo/Desktop/c3po/Images_aquises/Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>/home/marcpozzo/Desktop/c3po/Images_aquises/Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>autre</td>\n",
       "      <td>/home/marcpozzo/Desktop/c3po/Images_aquises/Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                          img_paths\n",
       "1      autre  /home/marcpozzo/Desktop/c3po/Images_aquises/Re...\n",
       "2  corneille  /home/marcpozzo/Desktop/c3po/Images_aquises/Re...\n",
       "3  corneille  /home/marcpozzo/Desktop/c3po/Images_aquises/Re...\n",
       "4     pigeon  /home/marcpozzo/Desktop/c3po/Images_aquises/Re...\n",
       "5      autre  /home/marcpozzo/Desktop/c3po/Images_aquises/Re..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9e4210d65866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m train_data_generator = ImageDataGenerator(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpreprocessing_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# data augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#rotation_range = 10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_input' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input\n",
    "        # data augmentation\n",
    "        #rotation_range = 10,\n",
    "        #zoom_range = zoom_range,\n",
    "        #horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    #preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_train) )\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_test))\n",
    "\n",
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First test the influence of number of epochs on the other recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       734\n",
      "           1       0.59      0.94      0.73        17\n",
      "           2       0.88      0.84      0.86       225\n",
      "           3       0.45      0.58      0.50        52\n",
      "           4       0.34      0.75      0.47        16\n",
      "           5       0.75      0.83      0.79       150\n",
      "\n",
      "    accuracy                           0.86      1194\n",
      "   macro avg       0.66      0.81      0.71      1194\n",
      "weighted avg       0.88      0.86      0.87      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       749\n",
      "           1       0.74      0.83      0.78        24\n",
      "           2       0.86      0.92      0.88       201\n",
      "           3       0.48      0.86      0.62        37\n",
      "           4       0.37      0.54      0.44        24\n",
      "           5       0.87      0.91      0.89       159\n",
      "\n",
      "    accuracy                           0.89      1194\n",
      "   macro avg       0.72      0.83      0.76      1194\n",
      "weighted avg       0.91      0.89      0.90      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       707\n",
      "           1       0.70      0.90      0.79        21\n",
      "           2       0.89      0.85      0.87       227\n",
      "           3       0.60      0.74      0.66        54\n",
      "           4       0.46      0.59      0.52        27\n",
      "           5       0.87      0.92      0.90       158\n",
      "\n",
      "    accuracy                           0.89      1194\n",
      "   macro avg       0.75      0.82      0.78      1194\n",
      "weighted avg       0.90      0.89      0.90      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       732\n",
      "           1       0.59      0.94      0.73        17\n",
      "           2       0.88      0.87      0.88       219\n",
      "           3       0.57      0.81      0.67        47\n",
      "           4       0.40      0.58      0.47        24\n",
      "           5       0.86      0.92      0.88       155\n",
      "\n",
      "    accuracy                           0.89      1194\n",
      "   macro avg       0.71      0.84      0.76      1194\n",
      "weighted avg       0.90      0.89      0.89      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=1000,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the influence of drop_out rate on other _recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96053   0.90997   0.93457       722\n",
      "           1    0.77778   0.80769   0.79245        26\n",
      "           2    0.86977   0.89048   0.88000       210\n",
      "           3    0.56716   0.74510   0.64407        51\n",
      "           4    0.57143   0.55556   0.56338        36\n",
      "           5    0.81325   0.90604   0.85714       149\n",
      "\n",
      "    accuracy                        0.88610      1194\n",
      "   macro avg    0.75999   0.80247   0.77860      1194\n",
      "weighted avg    0.89367   0.88610   0.88861      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96491   0.89918   0.93089       734\n",
      "           1    0.70370   0.86364   0.77551        22\n",
      "           2    0.89302   0.83843   0.86486       229\n",
      "           3    0.49254   0.76744   0.60000        43\n",
      "           4    0.45714   0.59259   0.51613        27\n",
      "           5    0.80120   0.95683   0.87213       139\n",
      "\n",
      "    accuracy                        0.88191      1194\n",
      "   macro avg    0.71875   0.81969   0.75992      1194\n",
      "weighted avg    0.89876   0.88191   0.88723      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.1)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96930   0.91575   0.94176       724\n",
      "           1    0.70370   0.90476   0.79167        21\n",
      "           2    0.89767   0.86161   0.87927       224\n",
      "           3    0.55224   0.80435   0.65487        46\n",
      "           4    0.60000   0.61765   0.60870        34\n",
      "           5    0.81928   0.93793   0.87460       145\n",
      "\n",
      "    accuracy                        0.89531      1194\n",
      "   macro avg    0.75703   0.84034   0.79181      1194\n",
      "weighted avg    0.90639   0.89531   0.89870      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.2)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97953   0.90541   0.94101       740\n",
      "           1    0.70370   0.90476   0.79167        21\n",
      "           2    0.88837   0.90094   0.89461       212\n",
      "           3    0.41791   0.77778   0.54369        36\n",
      "           4    0.54286   0.70370   0.61290        27\n",
      "           5    0.87952   0.92405   0.90123       158\n",
      "\n",
      "    accuracy                        0.89866      1194\n",
      "   macro avg    0.73532   0.85277   0.78085      1194\n",
      "weighted avg    0.91845   0.89866   0.90548      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.4)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95906   0.92786   0.94321       707\n",
      "           1    0.70370   0.90476   0.79167        21\n",
      "           2    0.89302   0.84581   0.86878       227\n",
      "           3    0.59701   0.74074   0.66116        54\n",
      "           4    0.45714   0.59259   0.51613        27\n",
      "           5    0.87349   0.91772   0.89506       158\n",
      "\n",
      "    accuracy                        0.89447      1194\n",
      "   macro avg    0.74724   0.82158   0.77933      1194\n",
      "weighted avg    0.90297   0.89447   0.89761      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.3)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97661   0.91758   0.94618       728\n",
      "           1    0.70370   0.90476   0.79167        21\n",
      "           2    0.88372   0.91346   0.89835       208\n",
      "           3    0.52239   0.83333   0.64220        42\n",
      "           4    0.68571   0.57143   0.62338        42\n",
      "           5    0.89157   0.96732   0.92790       153\n",
      "\n",
      "    accuracy                        0.90787      1194\n",
      "   macro avg    0.77728   0.85131   0.80494      1194\n",
      "weighted avg    0.91852   0.90787   0.91074      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.5)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97661   0.91758   0.94618       728\n",
      "           1    0.70370   0.90476   0.79167        21\n",
      "           2    0.88372   0.91346   0.89835       208\n",
      "           3    0.52239   0.83333   0.64220        42\n",
      "           4    0.68571   0.57143   0.62338        42\n",
      "           5    0.89157   0.96732   0.92790       153\n",
      "\n",
      "    accuracy                        0.90787      1194\n",
      "   macro avg    0.77728   0.85131   0.80494      1194\n",
      "weighted avg    0.91852   0.90787   0.91074      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.5)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96199   0.93333   0.94744       705\n",
      "           1    0.85185   0.95833   0.90196        24\n",
      "           2    0.91163   0.85965   0.88488       228\n",
      "           3    0.61194   0.82000   0.70085        50\n",
      "           4    0.48571   0.54839   0.51515        31\n",
      "           5    0.86145   0.91667   0.88820       156\n",
      "\n",
      "    accuracy                        0.90285      1194\n",
      "   macro avg    0.78076   0.83939   0.80641      1194\n",
      "weighted avg    0.91000   0.90285   0.90529      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.6)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98684   0.91588   0.95004       737\n",
      "           1    0.62963   0.94444   0.75556        18\n",
      "           2    0.91628   0.88739   0.90160       222\n",
      "           3    0.53731   0.85714   0.66055        42\n",
      "           4    0.51429   0.78261   0.62069        23\n",
      "           5    0.86145   0.94079   0.89937       152\n",
      "\n",
      "    accuracy                        0.90955      1194\n",
      "   macro avg    0.74097   0.88804   0.79797      1194\n",
      "weighted avg    0.92746   0.90955   0.91512      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.7)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97222   0.92361   0.94729       720\n",
      "           1    0.74074   0.95238   0.83333        21\n",
      "           2    0.92093   0.87225   0.89593       227\n",
      "           3    0.64179   0.86000   0.73504        50\n",
      "           4    0.57143   0.74074   0.64516        27\n",
      "           5    0.83735   0.93289   0.88254       149\n",
      "\n",
      "    accuracy                        0.90871      1194\n",
      "   macro avg    0.78074   0.88031   0.82322      1194\n",
      "weighted avg    0.91867   0.90871   0.91172      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.8)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96637   0.92707   0.94631       713\n",
      "           1    0.77778   0.80769   0.79245        26\n",
      "           2    0.94419   0.87879   0.91031       231\n",
      "           3    0.67164   0.86538   0.75630        52\n",
      "           4    0.45714   0.80000   0.58182        20\n",
      "           5    0.84337   0.92105   0.88050       152\n",
      "\n",
      "    accuracy                        0.90955      1194\n",
      "   macro avg    0.77675   0.86666   0.81128      1194\n",
      "weighted avg    0.92095   0.90955   0.91324      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6,0.9)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),verbose=0)\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
