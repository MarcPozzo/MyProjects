{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Refaire avec le grand écran\"\n",
    "import numpy as np # Pour la manipulation de tableaux\n",
    "from keras.applications import  resnet50\n",
    "from sklearn import metrics \n",
    "import os\n",
    "\n",
    "import pandas as pd # Pour manipuler des DataFrames pandas\n",
    "\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential # Pour construire un réseau de neurones\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Conv2D # Pour instancier une couche dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Activation,GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools # Pour créer des iterateurs\n",
    "\n",
    "from sklearn import linear_model, preprocessing \n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time, cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.1\n",
    "epochs=2\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.1\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "#df=pd.read_csv(\"/home/marcpozzo/Desktop/c3po/Images_aquises/generateur.csv\")\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5369 validated image filenames belonging to 6 classes.\n",
      "Found 597 validated image filenames belonging to 6 classes.\n",
      "5966\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        # data augmentation\n",
    "        rotation_range = 10,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n",
    "print(5369+597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Sequential()\n",
    "\n",
    "conv_1 = Conv2D(filters = 30,                     # Nombre de filtres\n",
    "                kernel_size = (5, 5),            # Dimensions du noyau\n",
    "                padding = 'valid',               # Mode de Dépassement\n",
    "                input_shape = (28, 28, 3),       # Dimensions de l'image en entrée\n",
    "                activation = 'relu')             # Fonction d'activation\n",
    "\n",
    "max_pool_1 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "conv_2 = Conv2D(filters = 16,                    \n",
    "                kernel_size = (3, 3),          \n",
    "                padding = 'valid',             \n",
    "                activation = 'relu')\n",
    "\n",
    "max_pool_2 = MaxPooling2D(pool_size = (2, 2))\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "dropout = Dropout(rate = dropout_rate)\n",
    "\n",
    "dense_1 = Dense(units = 128,\n",
    "                activation = 'relu')\n",
    "\n",
    "dense_2 = Dense(units = 6,\n",
    "                activation = 'softmax')\n",
    "\n",
    "lenet.add(conv_1)\n",
    "lenet.add(max_pool_1)\n",
    "lenet.add(conv_2)\n",
    "lenet.add(max_pool_2)\n",
    "lenet.add(dropout)\n",
    "lenet.add(flatten)\n",
    "lenet.add(dense_1)\n",
    "lenet.add(dense_2)\n",
    "\n",
    "# Compilation\n",
    "lenet.compile(loss='sparse_categorical_crossentropy',  # fonction de perte\n",
    "              optimizer='adam',                 # algorithme de descente de gradient\n",
    "              metrics=['accuracy'])             # métrique d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.5567 - accuracy: 0.4083 - val_loss: 44.6882 - val_accuracy: 0.5729\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 608us/step - loss: 1.2845 - accuracy: 0.6500 - val_loss: 58.0771 - val_accuracy: 0.5729\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 686us/step - loss: 1.2644 - accuracy: 0.6167 - val_loss: 28.9168 - val_accuracy: 0.5260\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 659us/step - loss: 1.2685 - accuracy: 0.5083 - val_loss: 32.4673 - val_accuracy: 0.5796\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 622us/step - loss: 1.3549 - accuracy: 0.5833 - val_loss: 51.3136 - val_accuracy: 0.5729\n",
      "Epoch 1\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 673us/step - loss: 1.2404 - accuracy: 0.6083 - val_loss: 40.7268 - val_accuracy: 0.5729\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 691us/step - loss: 1.1993 - accuracy: 0.6000 - val_loss: 27.7251 - val_accuracy: 0.5846\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 708us/step - loss: 1.1527 - accuracy: 0.6167 - val_loss: 37.0780 - val_accuracy: 0.5946\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 703us/step - loss: 1.1420 - accuracy: 0.6250 - val_loss: 37.1065 - val_accuracy: 0.6114\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 649us/step - loss: 1.1283 - accuracy: 0.6417 - val_loss: 34.9681 - val_accuracy: 0.6332\n",
      "Epoch 2\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 650us/step - loss: 1.0680 - accuracy: 0.6333 - val_loss: 35.6107 - val_accuracy: 0.6281\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 638us/step - loss: 1.3469 - accuracy: 0.5083 - val_loss: 25.2976 - val_accuracy: 0.6114\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 701us/step - loss: 1.0987 - accuracy: 0.6250 - val_loss: 28.6488 - val_accuracy: 0.6482\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 689us/step - loss: 1.0009 - accuracy: 0.7333 - val_loss: 41.7093 - val_accuracy: 0.6399\n",
      "Train on 120 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 645us/step - loss: 1.0126 - accuracy: 0.7000 - val_loss: 44.9376 - val_accuracy: 0.6466\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "#lenet.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "#                    steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "epochs=3\n",
    "longueur=round(len(x_train)/5)\n",
    "# here's a more \"manual\" example\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    #for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=longueur):\n",
    "        lenet.fit(x_batch, y_batch,validation_data=(x_test,y_test))\n",
    "        batches += 1\n",
    "        if batches >= len(x_train) / longueur:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
