{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different pre-trained models against the images used as \"test\" set during the training\n",
    "\n",
    "import numpy as np # Pour la manipulation de tableaux\n",
    "from keras.applications import  resnet50\n",
    "from sklearn import metrics \n",
    "import os\n",
    "\n",
    "import pandas as pd # Pour manipuler des DataFrames pandas\n",
    "\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential # Pour construire un réseau de neurones\n",
    "from keras.layers import Dense, Conv2D # Pour instancier une couche dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import keras\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools # Pour créer des iterateurs\n",
    "\n",
    "from sklearn import linear_model, preprocessing \n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time, cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n",
      "Found 5369 validated image filenames belonging to 6 classes.\n",
      "Found 597 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#Paramètres\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.1\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.1\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n",
    "\n",
    "#df=pd.read_csv(\"/home/marcpozzo/Desktop/c3po/Images_aquises/generateur.csv\")\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "df.shape\n",
    "df[df[\"img_paths\"]=='Rec_images_bigger/EK000414_3_pigeon_178.JPG']\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    \n",
    "df.shape\n",
    "df[df[\"img_paths\"]=='/home/marcpozzo/Desktop/c3po/Images_aquises/Rec_images_bigger/EK000414_3_pigeon_178.JPG']\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        # data augmentation\n",
    "        rotation_range = 10,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(X):\n",
    "    X_img=[]\n",
    "    for image in X:\n",
    "        # Load image\n",
    "        img=cv2.imread(image)\n",
    "        # Resize image\n",
    "        img=cv2.resize(img,(28,28))\n",
    "        # for the black and white image\n",
    "        if img.shape==(28, 28):\n",
    "            img=img.reshape([28,28,1])\n",
    "            img=np.concatenate([img,img,img],axis=2)\n",
    "        # cv2 load the image BGR sequence color (not RGB)\n",
    "        X_img.append(img[...,::-1])\n",
    "    return np.array(X_img)\n",
    "\n",
    "\n",
    "def metrique(arg_predict):\n",
    "    dictionnaire=train_generator.class_indices\n",
    "    dictionnaire_inv = {v: k for k, v in dictionnaire.items()}\n",
    "    \n",
    "    Keys=[]\n",
    "    Values=[]\n",
    "\n",
    "    for i in range(len(arg_predict)) :\n",
    "        Keys.append(arg_predict[i])\n",
    "        Values.append(dictionnaire_inv[arg_predict[i]])\n",
    "\n",
    "    #print(metrics.classification_report(Y_test, Values))\n",
    "    return Values\n",
    "\n",
    "X_train_img = convert_image(data_train.img_paths)\n",
    "Y_train = data_train['class']\n",
    "\n",
    "# Load the images test\n",
    "X_test_img = convert_image(data_test.img_paths)\n",
    "Y_test = data_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6c_rob               precision    recall  f1-score   support\n",
      "\n",
      "       autre       0.97      0.99      0.98       342\n",
      "   chevreuil       0.93      1.00      0.97        14\n",
      "   corneille       0.95      0.94      0.95       107\n",
      "      faisan       0.94      0.94      0.94        33\n",
      "       lapin       0.80      0.67      0.73        18\n",
      "      pigeon       1.00      0.99      0.99        83\n",
      "\n",
      "    accuracy                           0.97       597\n",
      "   macro avg       0.93      0.92      0.93       597\n",
      "weighted avg       0.97      0.97      0.97       597\n",
      "\n",
      "drop_out.50               precision    recall  f1-score   support\n",
      "\n",
      "       autre       0.94      0.99      0.96       342\n",
      "   chevreuil       0.75      0.86      0.80        14\n",
      "   corneille       0.93      0.93      0.93       107\n",
      "      faisan       0.87      0.82      0.84        33\n",
      "       lapin       0.90      0.50      0.64        18\n",
      "      pigeon       0.99      0.88      0.93        83\n",
      "\n",
      "    accuracy                           0.93       597\n",
      "   macro avg       0.90      0.83      0.85       597\n",
      "weighted avg       0.94      0.93      0.93       597\n",
      "\n",
      "z1.1               precision    recall  f1-score   support\n",
      "\n",
      "       autre       0.94      0.97      0.95       342\n",
      "   chevreuil       1.00      1.00      1.00        14\n",
      "   corneille       0.93      0.88      0.90       107\n",
      "      faisan       0.94      0.94      0.94        33\n",
      "       lapin       0.69      0.50      0.58        18\n",
      "      pigeon       0.91      0.88      0.90        83\n",
      "\n",
      "    accuracy                           0.93       597\n",
      "   macro avg       0.90      0.86      0.88       597\n",
      "weighted avg       0.93      0.93      0.93       597\n",
      "\n",
      "zoom_0.9:1.3_flip               precision    recall  f1-score   support\n",
      "\n",
      "       autre       0.97      0.99      0.98       342\n",
      "   chevreuil       1.00      1.00      1.00        14\n",
      "   corneille       0.94      0.95      0.94       107\n",
      "      faisan       0.90      0.85      0.88        33\n",
      "       lapin       0.88      0.78      0.82        18\n",
      "      pigeon       0.97      0.92      0.94        83\n",
      "\n",
      "    accuracy                           0.96       597\n",
      "   macro avg       0.94      0.91      0.93       597\n",
      "weighted avg       0.96      0.96      0.96       597\n",
      "\n",
      "zoom_1.3               precision    recall  f1-score   support\n",
      "\n",
      "       autre       0.96      0.97      0.96       342\n",
      "   chevreuil       0.88      1.00      0.93        14\n",
      "   corneille       0.90      0.95      0.93       107\n",
      "      faisan       0.93      0.85      0.89        33\n",
      "       lapin       0.83      0.56      0.67        18\n",
      "      pigeon       0.93      0.90      0.91        83\n",
      "\n",
      "    accuracy                           0.94       597\n",
      "   macro avg       0.90      0.87      0.88       597\n",
      "weighted avg       0.94      0.94      0.94       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Neurones=['6c_rob','drop_out.50','z1.1','zoom_0.9:1.3_flip','zoom_1.3']\n",
    "for n in Neurones:\n",
    "    model = load_model(n)\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    X_test_features = intermediate_layer_model.predict(preprocess_input(X_test_img))\n",
    "    arg_predict=X_test_features.argmax(axis=1)\n",
    "\n",
    "\n",
    "    pred=metrique(arg_predict)\n",
    "    print(n,metrics.classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagenet_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-468d4a88e59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imagenet_utils'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
