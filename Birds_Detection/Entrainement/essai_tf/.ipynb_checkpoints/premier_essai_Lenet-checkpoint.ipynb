{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(28, 28, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_2.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>corneille</td>\n",
       "      <td>Rec_images/DSCF0180_corneille_3.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0258_pigeon_4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0335_pigeon_8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>pigeon</td>\n",
       "      <td>Rec_images/DSCF0341_pigeon_10.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                            img_paths\n",
       "2   corneille  Rec_images/DSCF0180_corneille_2.JPG\n",
       "3   corneille  Rec_images/DSCF0180_corneille_3.JPG\n",
       "4      pigeon     Rec_images/DSCF0258_pigeon_4.JPG\n",
       "8      pigeon     Rec_images/DSCF0335_pigeon_8.JPG\n",
       "10     pigeon    Rec_images/DSCF0341_pigeon_10.JPG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/home/marcpozzo/Desktop/c3po/Images_aquises/generateur.csv\")\n",
    "df=df[(df[\"class\"]=='corneille') | (df[\"class\"]=='pigeon') | (df[\"class\"]=='faisan')   ]\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.2\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.3\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4772 validated image filenames belonging to 6 classes.\n",
      "Found 1194 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        #preprocessing_function = preprocess_input,\n",
    "        # data augmentation\n",
    "        rotation_range = 10,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator()\n",
    "    #preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_train) )\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_test))\n",
    "\n",
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4772 samples, validate on 1194 samples\n",
      "Epoch 1/3\n",
      "4772/4772 [==============================] - 3s 701us/sample - loss: 0.0362 - acc: 0.9889 - val_loss: 0.4167 - val_acc: 0.9188\n",
      "Epoch 2/3\n",
      "4772/4772 [==============================] - 3s 637us/sample - loss: 0.0480 - acc: 0.9853 - val_loss: 0.4317 - val_acc: 0.9079\n",
      "Epoch 3/3\n",
      "4772/4772 [==============================] - 3s 656us/sample - loss: 0.0754 - acc: 0.9757 - val_loss: 0.6895 - val_acc: 0.8233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f42afa2a410>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4772 samples, validate on 1194 samples\n",
      "4772/4772 [==============================] - 3s 657us/sample - loss: 0.0531 - acc: 0.9858 - val_loss: 0.4625 - val_acc: 0.9171\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.02437857907419214],\n",
       " 'acc': [0.99350375],\n",
       " 'val_loss': [0.43194546471888096],\n",
       " 'val_acc': [0.91457283]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2731\n",
      "           1       0.99      1.00      1.00       108\n",
      "           2       1.00      1.00      1.00       857\n",
      "           3       0.99      1.00      0.99       265\n",
      "           4       1.00      0.99      1.00       143\n",
      "           5       1.00      0.99      0.99       668\n",
      "\n",
      "    accuracy                           1.00      4772\n",
      "   macro avg       0.99      1.00      0.99      4772\n",
      "weighted avg       1.00      1.00      1.00      4772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       706\n",
      "           1       0.81      0.85      0.83        26\n",
      "           2       0.87      0.88      0.88       214\n",
      "           3       0.73      0.82      0.77        60\n",
      "           4       0.66      0.66      0.66        35\n",
      "           5       0.87      0.95      0.91       153\n",
      "\n",
      "    accuracy                           0.91      1194\n",
      "   macro avg       0.82      0.85      0.83      1194\n",
      "weighted avg       0.91      0.91      0.91      1194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "print(metrics.classification_report(y_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
