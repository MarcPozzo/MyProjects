{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un problème de vp ???\n",
    "#image_2019-06-15_10-47-26_1112_64_2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'abord vérifier si on a du Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing \n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn import metrics\n",
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "#generateur_path='/mnt/VegaSlowDataDisk/c3po/Chaine_de_traitement/Train_imagettes_annotées/type_oiseau/Materiel/generateur.csv'\n",
    "test_size=0.2\n",
    "\n",
    "\n",
    "epochs=200\n",
    "batch_size = 600\n",
    "zoom_range = 1.25\n",
    "horizontal_flip = True\n",
    "Minimum_Number_Class=100\n",
    "dropout_rate=0.3\n",
    "#steps_per_epoch=len(data_train)//batch_size\n",
    "steps_per_epoch=1\n",
    "#validation_steps=len(data_test)//batch_size\n",
    "validation_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 13\n",
      "img_paths: 6220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_img_paths=\"/home/marcpozzo/Desktop/c3po/Images_aquises/\"\n",
    "generateur_path='/mnt/VegaSlowDataDisk/c3po/Images_aquises/generateur_bigger.csv'\n",
    "\n",
    "df=pd.read_csv(generateur_path)\n",
    "df.drop('labels',inplace=True,axis=1)\n",
    "\n",
    "df[\"class\"].unique()\n",
    "for c in df:\n",
    "    print(''+c+':',len(df[c].unique()))\n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "All_Unique=df[\"class\"].unique()\n",
    "Utilisable=[]\n",
    "for i in df[\"class\"].unique():\n",
    "    if df[\"class\"][df[\"class\"]==i].count()>Minimum_Number_Class:\n",
    "        Utilisable.append(i)\n",
    "Utilisable\n",
    "Non_Utilisable=set(All_Unique)-set(Utilisable)\n",
    "Non_Utilisable\n",
    "for i in Non_Utilisable:\n",
    "    df=df[df[\"class\"]!=i]\n",
    "df=df[df[\"class\"]!=\"oiseau\"]  \n",
    "df[\"class\"].unique()\n",
    "\n",
    "\n",
    "for i in range(len(df[\"class\"])):\n",
    "    image_name=df[\"img_paths\"].iloc[i]\n",
    "    df[\"img_paths\"].iloc[i]=os.path.join(base_img_paths,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcpozzo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_path=\"/mnt/VegaSlowDataDisk/c3po_interface/bin/fp_images/\"\n",
    "\n",
    "\n",
    "\n",
    "fp_new=pd.read_csv(\"/mnt/VegaSlowDataDisk/c3po_interface/bin/fp_threshold/table_fp_new.csv\")\n",
    "\n",
    "liste_img_paths=[]\n",
    "for i in range(len(fp_new)):\n",
    "    liste_img_paths.append(n_path+fp_new[\"imagetteName\"].iloc[i])\n",
    "\n",
    "fp_new[\"img_paths\"]=liste_img_paths\n",
    "#imagetteNamefp_new.head()\n",
    "\n",
    "fp_new[\"class\"]=\"autre\"\n",
    "fp_new.columns\n",
    "\n",
    "to_drop=['path', 'filename', 'imagetteName', 'max_cat', 'cat', 'xmin', 'xmax','ymin', 'ymax', 'former_index']\n",
    "\n",
    "fp_new.drop(to_drop,axis=1,inplace=True)\n",
    "\n",
    "df=pd.concat([df,fp_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40827 validated image filenames belonging to 6 classes.\n",
      "Found 10207 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "data_train,data_test= train_test_split(df,stratify=df[\"class\"], test_size=test_size,random_state=42)\n",
    "train_data_generator = ImageDataGenerator()\n",
    "\n",
    "test_data_generator = ImageDataGenerator()\n",
    "    #preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=data_train,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_train) )\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=data_test,\n",
    "                                                          directory=\"\",\n",
    "                                                           x_col = \"img_paths\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (28 , 28), \n",
    "                                                          batch_size = len(data_test))\n",
    "\n",
    "gen=train_generator[0]\n",
    "\n",
    "x_train=gen[0]\n",
    "y_train=gen[1]\n",
    "\n",
    "\n",
    "\n",
    "gen_test=test_generator[0]\n",
    "\n",
    "x_test=gen_test[0]\n",
    "y_test=gen_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 39s 948us/sample - loss: 0.3675 - acc: 0.9053 - val_loss: 0.2370 - val_acc: 0.9540\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 37s 912us/sample - loss: 0.1399 - acc: 0.9622 - val_loss: 0.1656 - val_acc: 0.9607\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 34s 839us/sample - loss: 0.1108 - acc: 0.9688 - val_loss: 0.1305 - val_acc: 0.9622\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 35s 851us/sample - loss: 0.0911 - acc: 0.9732 - val_loss: 0.1231 - val_acc: 0.9681\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 34s 822us/sample - loss: 0.0825 - acc: 0.9764 - val_loss: 0.0804 - val_acc: 0.9778\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 33s 817us/sample - loss: 0.0701 - acc: 0.9788 - val_loss: 0.0638 - val_acc: 0.9812\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 33s 818us/sample - loss: 0.0622 - acc: 0.9810 - val_loss: 0.0641 - val_acc: 0.9830\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 34s 828us/sample - loss: 0.0588 - acc: 0.9817 - val_loss: 0.0726 - val_acc: 0.9803\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 34s 830us/sample - loss: 0.0552 - acc: 0.9826 - val_loss: 0.1607 - val_acc: 0.9680\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 34s 822us/sample - loss: 0.0486 - acc: 0.9850 - val_loss: 0.0784 - val_acc: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99804   0.98025   0.98906      9873\n",
      "           1    0.62963   0.89474   0.73913        19\n",
      "           2    0.64186   0.92617   0.75824       149\n",
      "           3    0.44776   0.90909   0.60000        33\n",
      "           4    0.40000   0.77778   0.52830        18\n",
      "           5    0.63855   0.92174   0.75445       115\n",
      "\n",
      "    accuracy                        0.97805     10207\n",
      "   macro avg    0.62597   0.90163   0.72820     10207\n",
      "weighted avg    0.98527   0.97805   0.98052     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 32s 795us/sample - loss: 0.0454 - acc: 0.9859 - val_loss: 0.0848 - val_acc: 0.9738\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 35s 854us/sample - loss: 0.0391 - acc: 0.9873 - val_loss: 0.0710 - val_acc: 0.9839\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 42s 1ms/sample - loss: 0.0347 - acc: 0.9889 - val_loss: 0.0543 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 40s 991us/sample - loss: 0.0335 - acc: 0.9887 - val_loss: 0.0885 - val_acc: 0.9769\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 39s 964us/sample - loss: 0.0320 - acc: 0.9897 - val_loss: 0.1030 - val_acc: 0.9739\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 43s 1ms/sample - loss: 0.0301 - acc: 0.9902 - val_loss: 0.0667 - val_acc: 0.9845\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 34s 838us/sample - loss: 0.0263 - acc: 0.9909 - val_loss: 0.0607 - val_acc: 0.9827\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 34s 841us/sample - loss: 0.0238 - acc: 0.9917 - val_loss: 0.0630 - val_acc: 0.9841\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 34s 827us/sample - loss: 0.0215 - acc: 0.9924 - val_loss: 0.0666 - val_acc: 0.9845\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 31s 761us/sample - loss: 0.0184 - acc: 0.9934 - val_loss: 0.1241 - val_acc: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99783   0.98164   0.98967      9857\n",
      "           1    0.81481   0.88000   0.84615        25\n",
      "           2    0.71628   0.92216   0.80628       167\n",
      "           3    0.44776   0.88235   0.59406        34\n",
      "           4    0.51429   0.62069   0.56250        29\n",
      "           5    0.51205   0.89474   0.65134        95\n",
      "\n",
      "    accuracy                        0.97825     10207\n",
      "   macro avg    0.66717   0.86360   0.74167     10207\n",
      "weighted avg    0.98505   0.97825   0.98064     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 30s 744us/sample - loss: 0.0200 - acc: 0.9936 - val_loss: 0.0580 - val_acc: 0.9845\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 28s 693us/sample - loss: 0.0173 - acc: 0.9941 - val_loss: 0.0638 - val_acc: 0.9864\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 30s 731us/sample - loss: 0.0163 - acc: 0.9944 - val_loss: 0.0684 - val_acc: 0.9859\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 30s 732us/sample - loss: 0.0122 - acc: 0.9958 - val_loss: 0.0826 - val_acc: 0.9801\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0135 - acc: 0.9951 - val_loss: 0.0741 - val_acc: 0.9840\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 29s 712us/sample - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0793 - val_acc: 0.9839\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 30s 738us/sample - loss: 0.0123 - acc: 0.9956 - val_loss: 0.0785 - val_acc: 0.9836\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 32s 794us/sample - loss: 0.0138 - acc: 0.9956 - val_loss: 0.1036 - val_acc: 0.9759\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 33s 807us/sample - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0655 - val_acc: 0.9863\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 37s 899us/sample - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0932 - val_acc: 0.9837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99629   0.98935   0.99281      9765\n",
      "           1    0.48148   0.92857   0.63415        14\n",
      "           2    0.89302   0.83478   0.86292       230\n",
      "           3    0.35821   0.96000   0.52174        25\n",
      "           4    0.54286   0.67857   0.60317        28\n",
      "           5    0.79518   0.91034   0.84887       145\n",
      "\n",
      "    accuracy                        0.98374     10207\n",
      "   macro avg    0.67784   0.88360   0.74394     10207\n",
      "weighted avg    0.98759   0.98374   0.98512     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 28s 695us/sample - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0736 - val_acc: 0.9847\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 28s 691us/sample - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0721 - val_acc: 0.9859\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 28s 682us/sample - loss: 0.0100 - acc: 0.9964 - val_loss: 0.0774 - val_acc: 0.9853\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 28s 694us/sample - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0889 - val_acc: 0.9835\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 37s 909us/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0865 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 31s 750us/sample - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0780 - val_acc: 0.9853\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 31s 747us/sample - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0810 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 35s 861us/sample - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0868 - val_acc: 0.9838\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 37s 917us/sample - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0749 - val_acc: 0.9856\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 29s 711us/sample - loss: 0.0061 - acc: 0.9978 - val_loss: 0.1044 - val_acc: 0.9824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99258   0.99074   0.99165      9715\n",
      "           1    0.70370   1.00000   0.82609        19\n",
      "           2    0.91628   0.76953   0.83652       256\n",
      "           3    0.47761   0.91429   0.62745        35\n",
      "           4    0.60000   0.70000   0.64615        30\n",
      "           5    0.80120   0.87500   0.83648       152\n",
      "\n",
      "    accuracy                        0.98237     10207\n",
      "   macro avg    0.74856   0.87493   0.79406     10207\n",
      "weighted avg    0.98435   0.98237   0.98288     10207\n",
      "\n",
      "Train on 40827 samples, validate on 10207 samples\n",
      "Epoch 1/10\n",
      "40827/40827 [==============================] - 29s 713us/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.1106 - val_acc: 0.9772\n",
      "Epoch 2/10\n",
      "40827/40827 [==============================] - 29s 708us/sample - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0862 - val_acc: 0.9857\n",
      "Epoch 3/10\n",
      "40827/40827 [==============================] - 29s 699us/sample - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0870 - val_acc: 0.9858\n",
      "Epoch 4/10\n",
      "40827/40827 [==============================] - 38s 920us/sample - loss: 0.0067 - acc: 0.9976 - val_loss: 0.1105 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "40827/40827 [==============================] - 35s 860us/sample - loss: 0.0069 - acc: 0.9976 - val_loss: 0.1649 - val_acc: 0.9796\n",
      "Epoch 6/10\n",
      "40827/40827 [==============================] - 37s 918us/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0739 - val_acc: 0.9872\n",
      "Epoch 7/10\n",
      "40827/40827 [==============================] - 31s 763us/sample - loss: 0.0050 - acc: 0.9982 - val_loss: 0.1026 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      "40827/40827 [==============================] - 33s 806us/sample - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0894 - val_acc: 0.9858\n",
      "Epoch 9/10\n",
      "40827/40827 [==============================] - 28s 678us/sample - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0931 - val_acc: 0.9854\n",
      "Epoch 10/10\n",
      "40827/40827 [==============================] - 28s 675us/sample - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0799 - val_acc: 0.9859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99361   0.99320   0.99340      9701\n",
      "           1    0.85185   0.88462   0.86792        26\n",
      "           2    0.89302   0.84581   0.86878       227\n",
      "           3    0.65672   0.84615   0.73950        52\n",
      "           4    0.68571   0.75000   0.71642        32\n",
      "           5    0.87349   0.85799   0.86567       169\n",
      "\n",
      "    accuracy                        0.98589     10207\n",
      "   macro avg    0.82573   0.86296   0.84195     10207\n",
      "weighted avg    0.98634   0.98589   0.98603     10207\n",
      "\n",
      "WARNING:tensorflow:From /home/marcpozzo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: m_min_fp/assets\n"
     ]
    }
   ],
   "source": [
    "val_acc=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "loss=[]\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "model = build_model(28, 28, 3, 6)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "y_predict=model.predict(x_test).argmax(axis=1)\n",
    "val_acc.append(history.history[\"val_acc\"])\n",
    "acc.append(history.history[\"acc\"])\n",
    "val_loss.append(history.history[\"val_loss\"])\n",
    "loss.append(history.history[\"loss\"])\n",
    "print(metrics.classification_report(y_predict,y_test,digits=5))\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"m_min_fp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
